import streamlit as st
import numpy as np
from sklearn.model_selection import train_test_split
from PIL import Image, ImageOps
import os
import mlflow
from datetime import datetime
from sklearn.datasets import fetch_openml
from sklearn.cluster import KMeans, DBSCAN
from sklearn.metrics import silhouette_score

def load_mnist():
    X = np.load("data/mnist/X.npy")
    return X

def data():
    st.header("MNIST Dataset")
    st.write("""
      **MNIST** lÃ  má»™t trong nhá»¯ng bá»™ dá»¯ liá»‡u ná»•i tiáº¿ng vÃ  phá»• biáº¿n nháº¥t trong cá»™ng Ä‘á»“ng há»c mÃ¡y, 
      Ä‘áº·c biá»‡t lÃ  trong cÃ¡c nghiÃªn cá»©u vá» nháº­n diá»‡n máº«u vÃ  phÃ¢n loáº¡i hÃ¬nh áº£nh.
  
      - Bá»™ dá»¯ liá»‡u bao gá»“m tá»•ng cá»™ng **70.000 áº£nh chá»¯ sá»‘ viáº¿t tay** tá»« **0** Ä‘áº¿n **9**, 
        má»—i áº£nh cÃ³ kÃ­ch thÆ°á»›c **28 x 28 pixel**.
      - Chia thÃ nh:
        - **Training set**: 60.000 áº£nh Ä‘á»ƒ huáº¥n luyá»‡n.
        - **Test set**: 10.000 áº£nh Ä‘á»ƒ kiá»ƒm tra.
      - Má»—i hÃ¬nh áº£nh lÃ  má»™t chá»¯ sá»‘ viáº¿t tay, Ä‘Æ°á»£c chuáº©n hÃ³a vÃ  chuyá»ƒn thÃ nh dáº¡ng grayscale (Ä‘en tráº¯ng).
  
      Dá»¯ liá»‡u nÃ y Ä‘Æ°á»£c sá»­ dá»¥ng rá»™ng rÃ£i Ä‘á»ƒ xÃ¢y dá»±ng cÃ¡c mÃ´ hÃ¬nh nháº­n diá»‡n chá»¯ sá»‘.
      """)

    st.subheader("Má»™t sá»‘ hÃ¬nh áº£nh tá»« MNIST Dataset")
    st.image("mnit.png", caption="Má»™t sá»‘ hÃ¬nh áº£nh tá»« MNIST Dataset", use_container_width=True)

    st.subheader("á»¨ng dá»¥ng thá»±c táº¿ cá»§a MNIST")
    st.write("""
      Bá»™ dá»¯ liá»‡u MNIST Ä‘Ã£ Ä‘Æ°á»£c sá»­ dá»¥ng trong nhiá»u á»©ng dá»¥ng nháº­n dáº¡ng chá»¯ sá»‘ viáº¿t tay, cháº³ng háº¡n nhÆ°:
      - Nháº­n diá»‡n sá»‘ trÃªn cÃ¡c hoÃ¡ Ä‘Æ¡n thanh toÃ¡n, biÃªn lai cá»­a hÃ ng.
      - Xá»­ lÃ½ chá»¯ sá»‘ trÃªn cÃ¡c bÆ°u kiá»‡n gá»­i qua bÆ°u Ä‘iá»‡n.
      - á»¨ng dá»¥ng trong cÃ¡c há»‡ thá»‘ng nháº­n diá»‡n tÃ i liá»‡u tá»± Ä‘á»™ng.
    """)

    st.subheader("VÃ­ dá»¥ vá» cÃ¡c mÃ´ hÃ¬nh há»c mÃ¡y vá»›i MNIST")
    st.write("""
      CÃ¡c mÃ´ hÃ¬nh há»c mÃ¡y phá»• biáº¿n Ä‘Ã£ Ä‘Æ°á»£c huáº¥n luyá»‡n vá»›i bá»™ dá»¯ liá»‡u MNIST bao gá»“m:
      - **Logistic Regression**
      - **Decision Trees**
      - **K-Nearest Neighbors (KNN)**
      - **Support Vector Machines (SVM)**
      - **Convolutional Neural Networks (CNNs)**
    """)




def split_data():
    st.title("ğŸ“Œ Chia dá»¯ liá»‡u (Unsupervised Learning)")

    # Táº£i dá»¯ liá»‡u MNIST
    X = load_mnist()
    total_samples = X.shape[0]
    if "clustering_split_done" not in st.session_state:
        st.session_state.clustering_split_done = False


    # Khá»Ÿi táº¡o cÃ¡c thuá»™c tÃ­nh trong session_state náº¿u chÆ°a tá»“n táº¡i
    if "test_size" not in st.session_state:
        st.session_state.test_size = 0.1  # GiÃ¡ trá»‹ máº·c Ä‘á»‹nh
    if "train_size" not in st.session_state:
        st.session_state.train_size = 0
    if "total_samples" not in st.session_state:
        st.session_state.total_samples = total_samples

    # Thanh kÃ©o chá»n sá»‘ lÆ°á»£ng áº£nh Ä‘á»ƒ sá»­ dá»¥ng
    num_samples = st.slider(
        "Chá»n sá»‘ lÆ°á»£ng áº£nh Ä‘á»ƒ sá»­ dá»¥ng:", 
        min_value=1000, 
        max_value=total_samples, 
        value=10000
    )

    # Thanh kÃ©o chá»n tá»· lá»‡ Train/Test (náº¿u cáº§n)
    test_size = st.slider(
        "Chá»n tá»· lá»‡ test (Äá»ƒ Ä‘Ã¡nh giÃ¡)", 
        min_value=0.0, 
        max_value=0.5, 
        value=0.1, 
        step=0.1
    )

    if st.button("âœ… XÃ¡c nháº­n & LÆ°u", key="split_data_confirm_button"):
        st.session_state.clustering_split_done = True  # ÄÃ¡nh dáº¥u Ä‘Ã£ chia dá»¯ liá»‡u
        st.success("âœ… Dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c chia thÃ nh cÃ´ng!")

        st.session_state.test_size = test_size
        st.session_state.train_size = num_samples * (1 - test_size)

        # Chá»n sá»‘ lÆ°á»£ng áº£nh mong muá»‘n
        X_selected = X[:num_samples]

        # Chia train/test (náº¿u test_size > 0)
        if test_size > 0:
            X_train, X_test = train_test_split(X_selected, test_size=test_size, random_state=42)
            st.session_state["clustering_X_train"] = X_train
            st.session_state["clustering_X_test"] = X_test
            st.success(f"ğŸ”¹ Dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c chia: Train ({len(X_train)}), Test ({len(X_test)})")
        else:
            # Náº¿u khÃ´ng chia test, sá»­ dá»¥ng toÃ n bá»™ dá»¯ liá»‡u
            st.session_state["clustering_X_train"] = X_selected
            st.session_state["clustering_X_test"] = np.array([])  # KhÃ´ng cÃ³ táº­p test
            st.success(f"ğŸ”¹ Dá»¯ liá»‡u Ä‘Ã£ sáºµn sÃ ng: {len(X_selected)} áº£nh")

    if "X_train" in st.session_state:
        st.write("ğŸ“Œ Dá»¯ liá»‡u Ä‘Ã£ sáºµn sÃ ng Ä‘á»ƒ sá»­ dá»¥ng!")


def mlflow_input():
    DAGSHUB_MLFLOW_URI = "https://dagshub.com/NewbieHocIT/MocMayvsPython.mlflow"
    st.session_state['mlflow_url'] = DAGSHUB_MLFLOW_URI
    mlflow.set_tracking_uri(DAGSHUB_MLFLOW_URI)

    os.environ["MLFLOW_TRACKING_USERNAME"] = "NewbieHocIT"
    os.environ["MLFLOW_TRACKING_PASSWORD"] = "681dda9a41f9271a144aa94fa8624153a3c95696"

    mlflow.set_experiment("Clustering")


def train():
    mlflow_input()

    # Kiá»ƒm tra xem dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c chia chÆ°a (sá»­ dá»¥ng key "clustering_X_train")
    if "clustering_X_train" not in st.session_state or "clustering_X_test" not in st.session_state:
        st.error("âš ï¸ ChÆ°a cÃ³ dá»¯ liá»‡u! HÃ£y chia dá»¯ liá»‡u trÆ°á»›c.")
        return

    # Láº¥y dá»¯ liá»‡u tá»« session_state
    X_train = st.session_state["clustering_X_train"]
    X_test = st.session_state["clustering_X_test"]

    # Chuáº©n hÃ³a dá»¯ liá»‡u
    X_train = X_train.reshape(-1, 28 * 28) / 255.0
    X_test = X_test.reshape(-1, 28 * 28) / 255.0 if X_test.size > 0 else None

    st.header("âš™ï¸ Chá»n mÃ´ hÃ¬nh & Huáº¥n luyá»‡n")

    model_choice = st.selectbox(
        "Chá»n mÃ´ hÃ¬nh:", 
        ["K-means", "DBSCAN"], 
        key="clustering_model_choice_selectbox"  # ThÃªm key duy nháº¥t
    )

    if model_choice == "K-means":
        st.markdown("""
        - **K-means** lÃ  má»™t thuáº­t toÃ¡n phÃ¢n cá»¥m dá»±a trÃªn khoáº£ng cÃ¡ch giá»¯a cÃ¡c Ä‘iá»ƒm dá»¯ liá»‡u.
        - **Tham sá»‘ cáº§n chá»n:**  
            - **n_clusters**: Sá»‘ lÆ°á»£ng cá»¥m.  
        """)
        n_clusters = st.slider(
            "n_clusters", 
            2, 20, 10, 
            key="clustering_n_clusters_slider"  # ThÃªm key duy nháº¥t
        )
        model = KMeans(n_clusters=n_clusters)

    elif model_choice == "DBSCAN":
        st.markdown("""
        - **DBSCAN** lÃ  má»™t thuáº­t toÃ¡n phÃ¢n cá»¥m dá»±a trÃªn máº­t Ä‘á»™.
        """)
        eps = st.slider(
            "eps (Khoáº£ng cÃ¡ch tá»‘i Ä‘a giá»¯a hai Ä‘iá»ƒm Ä‘á»ƒ coi lÃ  lÃ¢n cáº­n)", 
            0.01, 1.0, 0.5, 
            key="clustering_eps_slider"  # ThÃªm key duy nháº¥t
        )
        min_samples = st.slider(
            "min_samples (Sá»‘ lÆ°á»£ng Ä‘iá»ƒm tá»‘i thiá»ƒu trong má»™t lÃ¢n cáº­n)", 
            2, 20, 5, 
            key="clustering_min_samples_slider"  # ThÃªm key duy nháº¥t
        )
        model = DBSCAN(eps=eps, min_samples=min_samples)

    run_name = st.text_input(
        "ğŸ”¹ Nháº­p tÃªn Run:", 
        "Default_Run", 
        key="clustering_run_name_input"  # ThÃªm key duy nháº¥t
    )
    st.session_state["run_name"] = run_name if run_name else "default_run"

    if st.button("Huáº¥n luyá»‡n mÃ´ hÃ¬nh", key="clustering_train_button"):  # ThÃªm key duy nháº¥t
        with mlflow.start_run(run_name=f"Train_{st.session_state['run_name']}"):
            mlflow.log_param("test_size", st.session_state.test_size)
            mlflow.log_param("train_size", st.session_state.train_size)
            mlflow.log_param("num_samples", st.session_state.total_samples)

            progress_bar = st.progress(0)  # Thanh tiáº¿n trÃ¬nh
            status_text = st.empty()  # Hiá»ƒn thá»‹ tráº¡ng thÃ¡i tá»«ng bÆ°á»›c

            # BÆ°á»›c 1: Huáº¥n luyá»‡n mÃ´ hÃ¬nh
            status_text.text("â³ Äang huáº¥n luyá»‡n mÃ´ hÃ¬nh...")
            progress_bar.progress(30)

            model.fit(X_train)
            labels = model.labels_

            # BÆ°á»›c 2: TÃ­nh toÃ¡n silhouette score
            status_text.text("ğŸ“Š Äang tÃ­nh toÃ¡n silhouette score...")
            progress_bar.progress(60)

            if len(np.unique(labels)) > 1:
                silhouette_avg = silhouette_score(X_train, labels)
                st.success(f"ğŸ“Š **Silhouette Score**: {silhouette_avg:.4f}")
                mlflow.log_metric("silhouette_score", silhouette_avg)
            else:
                st.warning("âš  KhÃ´ng thá»ƒ tÃ­nh silhouette score vÃ¬ chá»‰ cÃ³ má»™t cá»¥m.")

            # BÆ°á»›c 3: Logging vá»›i MLflow
            status_text.text("ğŸ“ Äang ghi log vÃ o MLflow...")
            progress_bar.progress(80)

            mlflow.log_param("model", model_choice)
            if model_choice == "K-means":
                mlflow.log_param("n_clusters", n_clusters)
            elif model_choice == "DBSCAN":
                mlflow.log_param("eps", eps)
                mlflow.log_param("min_samples", min_samples)

            mlflow.sklearn.log_model(model, model_choice.lower())

            # BÆ°á»›c 4: LÆ°u mÃ´ hÃ¬nh vÃ o session_state
            status_text.text("ğŸ’¾ Äang lÆ°u mÃ´ hÃ¬nh...")
            progress_bar.progress(90)

            if "clustering_models" not in st.session_state:
                st.session_state["clustering_models"] = []

            model_name = model_choice.lower().replace(" ", "_")
            if model_choice == "DBSCAN":
                model_name += f"_eps{eps}_min_samples{min_samples}"
            elif model_choice == "K-means":
                model_name += f"_n_clusters{n_clusters}"

            existing_model = next((item for item in st.session_state["clustering_models"] if item["name"] == model_name), None)

            if existing_model:
                count = 1
                new_model_name = f"{model_name}_{count}"
                while any(item["name"] == new_model_name for item in st.session_state["clustering_models"]):
                    count += 1
                    new_model_name = f"{model_name}_{count}"
                model_name = new_model_name
                st.warning(f"âš ï¸ MÃ´ hÃ¬nh Ä‘Æ°á»£c lÆ°u vá»›i tÃªn: {model_name}")

            st.session_state["clustering_models"].append({"name": model_name, "model": model})
            st.write(f"ğŸ”¹ MÃ´ hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c lÆ°u vá»›i tÃªn: {model_name}")
            st.write(f"Tá»•ng sá»‘ mÃ´ hÃ¬nh hiá»‡n táº¡i: {len(st.session_state['clustering_models'])}")

            st.write("ğŸ“‹ Danh sÃ¡ch cÃ¡c mÃ´ hÃ¬nh Ä‘Ã£ lÆ°u:")
            model_names = [model["name"] for model in st.session_state["clustering_models"]]
            st.write(", ".join(model_names))

            st.success(f"âœ… ÄÃ£ log dá»¯ liá»‡u cho **Train_{st.session_state['run_name']}**!")
            status_text.text("ğŸ’¾ ÄÃ£ lÆ°u")
            progress_bar.progress(100)

from streamlit_drawable_canvas import st_canvas
from PIL import Image, ImageOps

def du_doan():
    st.title("ğŸ”¢ Dá»± Ä‘oÃ¡n phÃ¢n cá»¥m")

    # Kiá»ƒm tra xem Ä‘Ã£ cÃ³ mÃ´ hÃ¬nh chÆ°a
    if "clustering_models" not in st.session_state or not st.session_state["clustering_models"]:
        st.error("âš ï¸ ChÆ°a cÃ³ mÃ´ hÃ¬nh nÃ o Ä‘Æ°á»£c huáº¥n luyá»‡n. HÃ£y huáº¥n luyá»‡n mÃ´ hÃ¬nh trÆ°á»›c.")
        return

    # Chá»n mÃ´ hÃ¬nh
    model_names = [model["name"] for model in st.session_state["clustering_models"]]
    selected_model_name = st.selectbox("ğŸ” Chá»n mÃ´ hÃ¬nh Ä‘Ã£ huáº¥n luyá»‡n:", model_names)
    selected_model = next(model["model"] for model in st.session_state["clustering_models"] if model["name"] == selected_model_name)

    # Chá»n phÆ°Æ¡ng thá»©c nháº­p áº£nh
    input_option = st.radio("ğŸ–¼ Chá»n phÆ°Æ¡ng thá»©c nháº­p:", ["Táº£i lÃªn áº£nh", "Váº½ sá»‘"], 
                            horizontal=True,
                            key="input_option_radio"  # ThÃªm key
                            )

    img_array = None  # LÆ°u áº£nh Ä‘áº§u vÃ o

    if input_option == "Táº£i lÃªn áº£nh":
        uploaded_file = st.file_uploader("ğŸ“¤ Táº£i lÃªn áº£nh chá»¯ sá»‘ viáº¿t tay (28x28 pixel)", 
                                         type=["png", "jpg", "jpeg"],key="file_uploader" )
        if uploaded_file is not None:
            try:
                image = Image.open(uploaded_file).convert("L")
                image = ImageOps.invert(image)
                image = image.resize((28, 28))
                st.image(image, caption="áº¢nh Ä‘Ã£ táº£i lÃªn", use_column_width=False)

                img_array = np.array(image).reshape(1, -1) / 255.0

            except Exception as e:
                st.error(f"âŒ Lá»—i xá»­ lÃ½ áº£nh: {str(e)}")

    elif input_option == "Váº½ sá»‘":
        st.write("âœï¸ Váº½ sá»‘ bÃªn dÆ°á»›i (dÃ¹ng chuá»™t hoáº·c cáº£m á»©ng):")
        canvas_result = st_canvas(
            fill_color="black",
            stroke_width=10,
            stroke_color="white",
            background_color="black",
            width=280,
            height=280,
            drawing_mode="freedraw",
            key="canvas"
        )

        if canvas_result.image_data is not None:
            try:
                image = Image.fromarray((canvas_result.image_data[:, :, 0]).astype(np.uint8))
                image = image.resize((28, 28)).convert("L")
                image = ImageOps.invert(image)
                st.image(image, caption="áº¢nh váº½ Ä‘Ã£ Ä‘Æ°á»£c xá»­ lÃ½", use_column_width=False)

                img_array = np.array(image).reshape(1, -1) / 255.0

            except Exception as e:
                st.error(f"âŒ Lá»—i xá»­ lÃ½ áº£nh váº½ tay: {str(e)}")

    # NÃºt dá»± Ä‘oÃ¡n
    if img_array is not None:
        if st.button("ğŸš€ Dá»± Ä‘oÃ¡n",key="predict_button"):
            if isinstance(selected_model, DBSCAN):
                st.warning("âš ï¸ DBSCAN khÃ´ng há»— trá»£ dá»± Ä‘oÃ¡n trá»±c tiáº¿p.")
                st.write("ğŸ”¢ NhÃ£n cá»¥m tá»« quÃ¡ trÃ¬nh huáº¥n luyá»‡n:")
                st.write(selected_model.labels_)

                num_noise = np.sum(selected_model.labels_ == -1)
                st.write(f"ğŸ”¢ Sá»‘ lÆ°á»£ng Ä‘iá»ƒm nhiá»…u (noise): **{num_noise}**")

            elif isinstance(selected_model, KMeans):
                prediction = selected_model.predict(img_array)
                st.success(f"ğŸ”¢ Dá»± Ä‘oÃ¡n nhÃ£n cá»¥m: **{prediction[0]}**")
                st.write("ğŸ”¢ TÃ¢m cá»¥m (centroids):")
                st.write(selected_model.cluster_centers_)

            else:
                st.error("âš ï¸ MÃ´ hÃ¬nh khÃ´ng Ä‘Æ°á»£c há»— trá»£ trong chá»©c nÄƒng nÃ y.")

            # Hiá»ƒn thá»‹ thÃ´ng tin mÃ´ hÃ¬nh
            st.write("ğŸ“‹ **ThÃ´ng tin mÃ´ hÃ¬nh:**")
            st.write(f"- TÃªn mÃ´ hÃ¬nh: **{selected_model_name}**")
            st.write(f"- Loáº¡i mÃ´ hÃ¬nh: **{type(selected_model).__name__}**")



def show_experiment_selector():
    st.title("ğŸ“Š MLflow Experiments")

    experiment_name = "Clustering"
    
    # Láº¥y danh sÃ¡ch experiment
    experiments = mlflow.search_experiments()
    selected_experiment = next((exp for exp in experiments if exp.name == experiment_name), None)

    if not selected_experiment:
        st.error(f"âŒ Experiment '{experiment_name}' khÃ´ng tá»“n táº¡i!")
        return

    st.subheader(f"ğŸ“Œ Experiment: {experiment_name}")
    st.write(f"**Experiment ID:** {selected_experiment.experiment_id}")
    st.write(f"**Tráº¡ng thÃ¡i:** {'Active' if selected_experiment.lifecycle_stage == 'active' else 'Deleted'}")
    st.write(f"**Vá»‹ trÃ­ lÆ°u trá»¯:** {selected_experiment.artifact_location}")

    # Láº¥y danh sÃ¡ch runs trong experiment
    runs = mlflow.search_runs(experiment_ids=[selected_experiment.experiment_id])

    if runs.empty:
        st.warning("âš  KhÃ´ng cÃ³ runs nÃ o trong experiment nÃ y.")
        return

    st.write("### ğŸƒâ€â™‚ï¸ CÃ¡c Runs gáº§n Ä‘Ã¢y:")

    # Táº¡o danh sÃ¡ch run name vÃ  map vá»›i run_id
    run_dict = {}
    for _, run in runs.iterrows():
        run_name = run.get("tags.mlflow.runName", f"Run {run['run_id'][:8]}")
        run_dict[run_name] = run["run_id"]  # Map run_name -> run_id

    # Chá»n run theo tÃªn
    selected_run_name = st.selectbox("ğŸ” Chá»n má»™t run:", list(run_dict.keys()),key="run_selector_selectbox" )
    selected_run_id = run_dict[selected_run_name]

    # Láº¥y thÃ´ng tin cá»§a run Ä‘Ã£ chá»n
    selected_run = mlflow.get_run(selected_run_id)

    if selected_run:
        st.subheader(f"ğŸ“Œ ThÃ´ng tin Run: {selected_run_name}")
        st.write(f"**Run ID:** {selected_run_id}")
        st.write(f"**Tráº¡ng thÃ¡i:** {selected_run.info.status}")
        
        start_time_ms = selected_run.info.start_time
        start_time = datetime.fromtimestamp(start_time_ms / 1000).strftime("%Y-%m-%d %H:%M:%S") if start_time_ms else "KhÃ´ng cÃ³ thÃ´ng tin"

        st.write(f"**Thá»i gian cháº¡y:** {start_time}")

        params = selected_run.data.params
        metrics = selected_run.data.metrics

        if params:
            st.write("### âš™ï¸ Parameters:")
            st.json(params)

        if metrics:
            st.write("### ğŸ“Š Metrics:")
            st.json(metrics)

    else:
        st.warning("âš  KhÃ´ng tÃ¬m tháº¥y thÃ´ng tin cho run nÃ y.")


def Clustering():
    st.title("ğŸ–Šï¸ MNIST Clustering App")

    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“˜ Data", "âš™ï¸ Huáº¥n luyá»‡n", "ğŸ”¢ Dá»± Ä‘oÃ¡n", "ğŸ”¥Mlflow"])

    with tab1:
        data()
        
    with tab2:
        split_data()
        train()
        
    with tab3:
        du_doan()   
    with tab4:
        show_experiment_selector()  

if __name__ == "__main__":
    Clustering()