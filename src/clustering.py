import streamlit as st
import numpy as np
from sklearn.model_selection import train_test_split
from PIL import Image, ImageOps
import os
import mlflow
from datetime import datetime
from sklearn.datasets import fetch_openml
from sklearn.cluster import KMeans, DBSCAN
from sklearn.metrics import silhouette_score

def load_mnist():
    X = np.load("data/mnist/X.npy")
    return X

def data():
    st.header("MNIST Dataset")
    st.write("""
      **MNIST** l√† m·ªôt trong nh·ªØng b·ªô d·ªØ li·ªáu n·ªïi ti·∫øng v√† ph·ªï bi·∫øn nh·∫•t trong c·ªông ƒë·ªìng h·ªçc m√°y, 
      ƒë·∫∑c bi·ªát l√† trong c√°c nghi√™n c·ª©u v·ªÅ nh·∫≠n di·ªán m·∫´u v√† ph√¢n lo·∫°i h√¨nh ·∫£nh.
  
      - B·ªô d·ªØ li·ªáu bao g·ªìm t·ªïng c·ªông **70.000 ·∫£nh ch·ªØ s·ªë vi·∫øt tay** t·ª´ **0** ƒë·∫øn **9**, 
        m·ªói ·∫£nh c√≥ k√≠ch th∆∞·ªõc **28 x 28 pixel**.
      - Chia th√†nh:
        - **Training set**: 60.000 ·∫£nh ƒë·ªÉ hu·∫•n luy·ªán.
        - **Test set**: 10.000 ·∫£nh ƒë·ªÉ ki·ªÉm tra.
      - M·ªói h√¨nh ·∫£nh l√† m·ªôt ch·ªØ s·ªë vi·∫øt tay, ƒë∆∞·ª£c chu·∫©n h√≥a v√† chuy·ªÉn th√†nh d·∫°ng grayscale (ƒëen tr·∫Øng).
  
      D·ªØ li·ªáu n√†y ƒë∆∞·ª£c s·ª≠ d·ª•ng r·ªông r√£i ƒë·ªÉ x√¢y d·ª±ng c√°c m√¥ h√¨nh nh·∫≠n di·ªán ch·ªØ s·ªë.
      """)

    st.subheader("M·ªôt s·ªë h√¨nh ·∫£nh t·ª´ MNIST Dataset")
    st.image("mnit.png", caption="M·ªôt s·ªë h√¨nh ·∫£nh t·ª´ MNIST Dataset", use_container_width=True)

    st.subheader("·ª®ng d·ª•ng th·ª±c t·∫ø c·ªßa MNIST")
    st.write("""
      B·ªô d·ªØ li·ªáu MNIST ƒë√£ ƒë∆∞·ª£c s·ª≠ d·ª•ng trong nhi·ªÅu ·ª©ng d·ª•ng nh·∫≠n d·∫°ng ch·ªØ s·ªë vi·∫øt tay, ch·∫≥ng h·∫°n nh∆∞:
      - Nh·∫≠n di·ªán s·ªë tr√™n c√°c ho√° ƒë∆°n thanh to√°n, bi√™n lai c·ª≠a h√†ng.
      - X·ª≠ l√Ω ch·ªØ s·ªë tr√™n c√°c b∆∞u ki·ªán g·ª≠i qua b∆∞u ƒëi·ªán.
      - ·ª®ng d·ª•ng trong c√°c h·ªá th·ªëng nh·∫≠n di·ªán t√†i li·ªáu t·ª± ƒë·ªông.
    """)

    st.subheader("V√≠ d·ª• v·ªÅ c√°c m√¥ h√¨nh h·ªçc m√°y v·ªõi MNIST")
    st.write("""
      C√°c m√¥ h√¨nh h·ªçc m√°y ph·ªï bi·∫øn ƒë√£ ƒë∆∞·ª£c hu·∫•n luy·ªán v·ªõi b·ªô d·ªØ li·ªáu MNIST bao g·ªìm:
      - **Logistic Regression**
      - **Decision Trees**
      - **K-Nearest Neighbors (KNN)**
      - **Support Vector Machines (SVM)**
      - **Convolutional Neural Networks (CNNs)**
    """)




from sklearn.metrics.pairwise import euclidean_distances
import numpy as np

def split_data():
    st.title("üìå Chia d·ªØ li·ªáu (Unsupervised Learning)")

    # T·∫£i d·ªØ li·ªáu MNIST
    X = load_mnist()
    total_samples = X.shape[0]
    if "clustering_split_done" not in st.session_state:
        st.session_state.clustering_split_done = False

    # Kh·ªüi t·∫°o c√°c thu·ªôc t√≠nh trong session_state n·∫øu ch∆∞a t·ªìn t·∫°i
    if "test_size" not in st.session_state:
        st.session_state.test_size = 0.1  # Gi√° tr·ªã m·∫∑c ƒë·ªãnh
    if "train_size" not in st.session_state:
        st.session_state.train_size = 0
    if "total_samples" not in st.session_state:
        st.session_state.total_samples = total_samples

    # Thanh k√©o ch·ªçn s·ªë l∆∞·ª£ng ·∫£nh ƒë·ªÉ s·ª≠ d·ª•ng
    num_samples = st.number_input("üìå Nh·∫≠p s·ªë l∆∞·ª£ng ·∫£nh ƒë·ªÉ train:", min_value=1000, max_value=70000, value=20000, step=1000)



    if st.button("‚úÖ X√°c nh·∫≠n & L∆∞u", key="split_data_confirm_button"):
        st.session_state.clustering_split_done = True  # ƒê√°nh d·∫•u ƒë√£ chia d·ªØ li·ªáu
        st.success("‚úÖ D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c chia th√†nh c√¥ng!")

        st.session_state.train_size = num_samples

        # Ch·ªçn s·ªë l∆∞·ª£ng ·∫£nh mong mu·ªën
        X_selected = X[:num_samples]

        # Chia train/test (n·∫øu test_size > 0)
        # N·∫øu kh√¥ng chia test, s·ª≠ d·ª•ng to√†n b·ªô d·ªØ li·ªáu
        st.session_state["clustering_X_train"] = X_selected
        st.session_state["clustering_X_test"] = np.array([])  # Kh√¥ng c√≥ t·∫≠p test
        st.success(f"üîπ D·ªØ li·ªáu ƒë√£ s·∫µn s√†ng: {len(X_selected)} ·∫£nh")

    if "X_train" in st.session_state:
        st.write("üìå D·ªØ li·ªáu ƒë√£ s·∫µn s√†ng ƒë·ªÉ s·ª≠ d·ª•ng!")



def mlflow_input():
    DAGSHUB_MLFLOW_URI = "https://dagshub.com/NewbieHocIT/MocMayvsPython.mlflow"
    st.session_state['mlflow_url'] = DAGSHUB_MLFLOW_URI
    mlflow.set_tracking_uri(DAGSHUB_MLFLOW_URI)

    os.environ["MLFLOW_TRACKING_USERNAME"] = "NewbieHocIT"
    os.environ["MLFLOW_TRACKING_PASSWORD"] = "681dda9a41f9271a144aa94fa8624153a3c95696"

    mlflow.set_experiment("Clustering")


def train():
    mlflow_input()

    # Ki·ªÉm tra d·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c chia ch∆∞a
    if "clustering_X_train" not in st.session_state or "clustering_X_test" not in st.session_state:
        st.error("‚ö†Ô∏è Ch∆∞a c√≥ d·ªØ li·ªáu! H√£y chia d·ªØ li·ªáu tr∆∞·ªõc.")
        return

    X_train = st.session_state["clustering_X_train"]
    X_test = st.session_state["clustering_X_test"]

    # Chu·∫©n h√≥a d·ªØ li·ªáu
    X_train = X_train.reshape(-1, 28 * 28) / 255.0
    X_test = X_test.reshape(-1, 28 * 28) / 255.0 if X_test.size > 0 else None

    st.header("‚öôÔ∏è Ch·ªçn m√¥ h√¨nh & Hu·∫•n luy·ªán")

    model_choice = st.selectbox("Ch·ªçn m√¥ h√¨nh:", ["K-means", "DBSCAN"], key="clustering_model_choice_selectbox")

    if model_choice == "K-means":
        n_clusters = st.slider("n_clusters", 2, 20, 10, key="clustering_n_clusters_slider")
        model = KMeans(n_clusters=n_clusters)
    elif model_choice == "DBSCAN":
        # Tham s·ªë m·∫∑c ƒë·ªãnh t·ªët h∆°n cho DBSCAN v·ªõi MNIST
        eps = st.slider("eps (Kho·∫£ng c√°ch t·ªëi ƒëa gi·ªØa hai ƒëi·ªÉm ƒë·ªÉ coi l√† l√¢n c·∫≠n)", 0.1, 10.0, 4.2, step=0.1, key="clustering_eps_slider")
        min_samples = st.slider("min_samples (S·ªë l∆∞·ª£ng ƒëi·ªÉm t·ªëi thi·ªÉu trong m·ªôt l√¢n c·∫≠n)", 2, 50, 10, key="clustering_min_samples_slider")
        model = DBSCAN(eps=eps, min_samples=min_samples)

    run_name = st.text_input("üîπ Nh·∫≠p t√™n Run:", "Default_Run", key="clustering_run_name_input")
    st.session_state["run_name"] = run_name if run_name else "default_run"

    if st.button("Hu·∫•n luy·ªán m√¥ h√¨nh", key="clustering_train_button"):
        with mlflow.start_run(run_name=f"Train_{st.session_state['run_name']}"):
            # C√°c b∆∞·ªõc log param nh∆∞ c≈©
            mlflow.log_param("test_size", st.session_state.test_size)
            mlflow.log_param("train_size", st.session_state.train_size)
            mlflow.log_param("num_samples", st.session_state.total_samples)

            progress_bar = st.progress(0)
            status_text = st.empty()



    # Hu·∫•n luy·ªán m√¥ h√¨nh
            status_text.text("‚è≥ ƒêang hu·∫•n luy·ªán m√¥ h√¨nh...")
            start_time = time.time()
            model.fit(X_train)
            training_time = time.time() - start_time
            labels = model.labels_ if hasattr(model, "labels_") else model.predict(X_train)
            st.session_state["clustering_labels"] = labels

            # Gi·∫£ l·∫≠p thanh ti·∫øn tr√¨nh m∆∞·ª£t m√†
            total_steps = 100
            for i in range(total_steps + 1):
                progress = min(i / total_steps, 0.5)  # 0% -> 50% cho hu·∫•n luy·ªán
                progress_bar.progress(progress)
                time.sleep(training_time / (2 * total_steps))  # ƒêi·ªÅu ch·ªânh t·ªëc ƒë·ªô d·ª±a tr√™n th·ªùi gian th·ª±c

            # T√≠nh silhouette score
            status_text.text("üìä ƒêang t√≠nh to√°n silhouette score...")
            if len(np.unique(labels)) > 1 and -1 not in labels:
                silhouette_avg = silhouette_score(X_train, labels)
                st.success(f"üìä **Silhouette Score**: {silhouette_avg:.4f}")
                mlflow.log_metric("silhouette_score", silhouette_avg)
            # Ti·∫øp t·ª•c tƒÉng progress t·ª´ 50% ƒë·∫øn 80%
            for i in range(total_steps // 2, int(total_steps * 0.8)):
                progress = i / total_steps
                progress_bar.progress(progress)
                time.sleep(0.01)

            # Logging MLflow v√† l∆∞u m√¥ h√¨nh
            status_text.text("üìù ƒêang ghi log v√†o MLflow...")
            mlflow.log_param("model", model_choice)
            if model_choice == "K-means":
                mlflow.log_param("n_clusters", n_clusters)
            elif model_choice == "DBSCAN":
                mlflow.log_param("eps", eps)
                mlflow.log_param("min_samples", min_samples)
            mlflow.sklearn.log_model(model, model_choice.lower())

            # Ti·∫øn tr√¨nh t·ª´ 80% ƒë·∫øn 100%
            status_text.text("üíæ ƒêang l∆∞u m√¥ h√¨nh...")
            for i in range(int(total_steps * 0.8), total_steps + 1):
                progress = i / total_steps
                progress_bar.progress(progress)
                time.sleep(0.01)

            if "clustering_models" not in st.session_state:
                st.session_state["clustering_models"] = []

            model_name = model_choice.lower().replace(" ", "_")
            if model_choice == "DBSCAN":
                model_name += f"_eps{eps}_min_samples{min_samples}"
            elif model_choice == "K-means":
                model_name += f"_n_clusters{n_clusters}"

            existing_model = next((item for item in st.session_state["clustering_models"] if item["name"] == model_name), None)

            if existing_model:
                count = 1
                new_model_name = f"{model_name}_{count}"
                while any(item["name"] == new_model_name for item in st.session_state["clustering_models"]):
                    count += 1
                    new_model_name = f"{model_name}_{count}"
                model_name = new_model_name
                st.warning(f"‚ö†Ô∏è M√¥ h√¨nh ƒë∆∞·ª£c l∆∞u v·ªõi t√™n: {model_name}")

            st.session_state["clustering_models"].append({"name": model_name, "model": model})

            # Hi·ªÉn th·ªã th√¥ng tin b·ªï sung cho DBSCAN
            if model_choice == "DBSCAN":
                num_clusters = len(set(labels)) - (1 if -1 in labels else 0)
                num_noise = list(labels).count(-1)
                st.write(f"üî¢ S·ªë l∆∞·ª£ng c·ª•m: {num_clusters}")
                st.write(f"üî¢ S·ªë l∆∞·ª£ng ƒëi·ªÉm nhi·ªÖu: {num_noise}")

            # Hi·ªÉn th·ªã silhouette score (n·∫øu ƒë√£ t√≠nh)
            if "silhouette_avg" in locals() and len(np.unique(labels)) > 1 and -1 not in labels:
                st.write(f"üìä **Silhouette Score**: {silhouette_avg:.4f}")
            elif model_choice == "DBSCAN" and -1 in labels:
                # T√≠nh silhouette score lo·∫°i b·ªè nhi·ªÖu cho DBSCAN
                if num_clusters > 1:  # Ch·ªâ t√≠nh n·∫øu c√≥ h∆°n 1 c·ª•m h·ª£p l·ªá
                    mask = labels != -1  # L·ªçc b·ªè c√°c ƒëi·ªÉm nhi·ªÖu
                    if mask.sum() > 0:  # ƒê·∫£m b·∫£o c√≤n d·ªØ li·ªáu sau khi l·ªçc
                        silhouette_avg_no_noise = silhouette_score(X_train[mask], labels[mask])
                        st.write(f"üìä **Silhouette Score**: {silhouette_avg_no_noise:.4f}")
                    else:
                        st.write("üìä Kh√¥ng th·ªÉ t√≠nh Silhouette Score: Kh√¥ng ƒë·ªß ƒëi·ªÉm d·ªØ li·ªáu sau khi lo·∫°i b·ªè nhi·ªÖu.")
                else:
                    st.write("üìä Kh√¥ng th·ªÉ t√≠nh Silhouette Score: Ch·ªâ c√≥ 1 c·ª•m ho·∫∑c to√†n b·ªô l√† nhi·ªÖu.")
            else:
                st.write("üìä Kh√¥ng th·ªÉ t√≠nh Silhouette Score: Ch·ªâ c√≥ 1 c·ª•m.")

            st.write(f"üîπ M√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c l∆∞u v·ªõi t√™n: {model_name}")
            st.write(f"T·ªïng s·ªë m√¥ h√¨nh hi·ªán t·∫°i: {len(st.session_state['clustering_models'])}")

            st.write("üìã Danh s√°ch c√°c m√¥ h√¨nh ƒë√£ l∆∞u:")
            model_names = [model["name"] for model in st.session_state["clustering_models"]]
            st.write(", ".join(model_names))

            st.success(f"‚úÖ ƒê√£ log d·ªØ li·ªáu cho **Train_{st.session_state['run_name']}**!")
            status_text.text("üíæ ƒê√£ l∆∞u")
            progress_bar.progress(100)
            
import streamlit as st
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
from sklearn.cluster import KMeans, DBSCAN
import plotly.express as px

import time  # Th√™m th∆∞ vi·ªán time ƒë·ªÉ m√¥ ph·ªèng ti·∫øn tr√¨nh

import plotly.express as px
from sklearn.decomposition import PCA
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import streamlit as st
from sklearn.cluster import KMeans, DBSCAN
import time

def visualize_clusters():
    st.title("üî¢ Tr·ª±c quan h√≥a c√°c c·ª•m t·ª´ m√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán")

    # Ki·ªÉm tra m√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán
    if "clustering_models" not in st.session_state or not st.session_state["clustering_models"]:
        st.error("‚ö†Ô∏è Ch∆∞a c√≥ m√¥ h√¨nh n√†o ƒë∆∞·ª£c hu·∫•n luy·ªán. H√£y hu·∫•n luy·ªán m√¥ h√¨nh tr∆∞·ªõc.")
        return

    # Ch·ªçn m√¥ h√¨nh
    model_names = [model["name"] for model in st.session_state["clustering_models"]]
    selected_model_name = st.selectbox("üîç Ch·ªçn m√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán:", model_names)
    selected_model = next(model["model"] for model in st.session_state["clustering_models"] if model["name"] == selected_model_name)

    # Ki·ªÉm tra n·∫øu ƒë√£ c√≥ nh√£n c·ª•m t·ª´ qu√° tr√¨nh hu·∫•n luy·ªán
    if "clustering_labels" not in st.session_state:
        st.error("‚ö†Ô∏è Ch∆∞a c√≥ nh√£n c·ª•m ƒë∆∞·ª£c l∆∞u. H√£y ƒë·∫£m b·∫£o m√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c hu·∫•n luy·ªán v√† l∆∞u nh√£n.")
        return
    
    labels = st.session_state["clustering_labels"]

    # Ch·ªçn ki·ªÉu tr·ª±c quan
    plot_type = st.radio("Ch·ªçn ki·ªÉu tr·ª±c quan:", ["2D", "3D"])

    # N√∫t b·∫Øt ƒë·∫ßu tr·ª±c quan h√≥a
    if st.button("B·∫Øt ƒë·∫ßu tr·ª±c quan h√≥a"):
        # Kh·ªüi t·∫°o thanh ti·∫øn tr√¨nh v√† tr·∫°ng th√°i
        progress_bar = st.progress(0)
        status_text = st.empty()

        # B∆∞·ªõc 1: Gi·∫£m chi·ªÅu d·ªØ li·ªáu b·∫±ng PCA
        status_text.text("‚è≥ ƒêang gi·∫£m chi·ªÅu d·ªØ li·ªáu...")
        for percent_complete in range(20):  # TƒÉng d·∫ßn t·ª´ 0% ƒë·∫øn 20%
            time.sleep(0.05)
            progress_bar.progress(percent_complete + 1)

        # L·∫•y d·ªØ li·ªáu t·ª´ session_state
        X_train = st.session_state["clustering_X_train"]
        X_train = X_train.reshape(-1, 28 * 28) / 255.0

        # Gi·∫£m chi·ªÅu xu·ªëng 3D b·∫±ng PCA
        reducer = PCA(n_components=3, random_state=42)
        X_reduced = reducer.fit_transform(X_train)

        # B∆∞·ªõc 2: Chu·∫©n b·ªã d·ªØ li·ªáu
        status_text.text("‚è≥ ƒêang chu·∫©n b·ªã d·ªØ li·ªáu ƒë·ªÉ v·∫Ω bi·ªÉu ƒë·ªì...")
        for percent_complete in range(20, 50):  # TƒÉng d·∫ßn t·ª´ 20% ƒë·∫øn 50%
            time.sleep(0.05)
            progress_bar.progress(percent_complete + 1)

        # T·∫£i nh√£n g·ªëc t·ª´ MNIST (gi·∫£ ƒë·ªãnh b·∫°n c√≥ h√†m load_mnist tr·∫£ v·ªÅ X v√† y)
        from sklearn.datasets import fetch_openml
        X_mnist, y_mnist = fetch_openml('mnist_784', version=1, return_X_y=True, as_frame=False)
        y_mnist = y_mnist[:len(X_train)].astype(int)  # Ch·ªâ l·∫•y s·ªë l∆∞·ª£ng t∆∞∆°ng ·ª©ng v·ªõi X_train

        # Chuy·ªÉn th√†nh DataFrame
        df = pd.DataFrame(X_reduced, columns=['X1', 'X2', 'X3'])
        df['Cluster'] = labels.astype(str)  # Chuy·ªÉn nh√£n c·ª•m th√†nh chu·ªói ƒë·ªÉ Plotly coi l√† ph√¢n lo·∫°i
        df['Original_Label'] = y_mnist  # Nh√£n g·ªëc t·ª´ MNIST

        # B∆∞·ªõc 3: V·∫Ω bi·ªÉu ƒë·ªì
        status_text.text("‚è≥ ƒêang v·∫Ω bi·ªÉu ƒë·ªì...")
        for percent_complete in range(50, 90):  # TƒÉng d·∫ßn t·ª´ 50% ƒë·∫øn 90%
            time.sleep(0.05)
            progress_bar.progress(percent_complete + 1)

        if plot_type == "2D":
            plt.figure(figsize=(10, 8))
            sns.scatterplot(x='X1', y='X2', hue='Cluster', data=df, palette='tab10', legend='full')
            plt.xlabel("X1")
            plt.ylabel("X2")
            plt.title("Tr·ª±c quan h√≥a c·ª•m b·∫±ng PCA (2D)")
            st.pyplot(plt)
        else:
            # T√πy ch·ªânh bi·ªÉu ƒë·ªì 3D v·ªõi m√†u ri√™ng bi·ªát cho t·ª´ng c·ª•m
            fig = px.scatter_3d(
                df, 
                x='X1', 
                y='X2', 
                z='X3', 
                color='Cluster',  # M√†u theo c·ª•m (ph√¢n lo·∫°i)
                title="Tr·ª±c quan h√≥a c·ª•m b·∫±ng PCA (3D)",
                hover_data={'Original_Label': True, 'Cluster': True},  # Hi·ªÉn th·ªã nh√£n g·ªëc v√† nh√£n d·ª± ƒëo√°n khi hover
                opacity=0.7,  # ƒê·ªô trong su·ªët ƒë·ªÉ d·ªÖ nh√¨n
                symbol='Cluster',  # D√πng bi·ªÉu t∆∞·ª£ng kh√°c nhau cho t·ª´ng c·ª•m (t√πy ch·ªçn)
            )
            # T√πy ch·ªânh giao di·ªán
            fig.update_traces(marker=dict(size=5))  # K√≠ch th∆∞·ªõc ƒëi·ªÉm
            fig.update_layout(
                scene=dict(
                    xaxis_title='X1',
                    yaxis_title='X2',
                    zaxis_title='X3',
                    bgcolor='rgba(0,0,0,0)',  # N·ªÅn trong su·ªët
                ),
                margin=dict(l=0, r=0, b=0, t=40),  # Gi·∫£m l·ªÅ
                title_x=0.5,  # CƒÉn gi·ªØa ti√™u ƒë·ªÅ
                legend_title_text='C·ª•m',  # Ti√™u ƒë·ªÅ legend
                coloraxis_showscale=False,  # ·∫®n thanh m√†u gradient
            )
            st.plotly_chart(fig, use_container_width=True)

        # B∆∞·ªõc 4: Hi·ªÉn th·ªã th√¥ng tin m√¥ h√¨nh
        status_text.text("‚è≥ ƒêang hi·ªÉn th·ªã th√¥ng tin m√¥ h√¨nh...")
        for percent_complete in range(90, 100):  # TƒÉng d·∫ßn t·ª´ 90% ƒë·∫øn 100%
            time.sleep(0.05)
            progress_bar.progress(percent_complete + 1)

        # Hi·ªÉn th·ªã th√¥ng tin m√¥ h√¨nh
        st.write("üìã **Th√¥ng tin m√¥ h√¨nh:**")
        st.write(f"- T√™n m√¥ h√¨nh: **{selected_model_name}**")
        st.write(f"- Lo·∫°i m√¥ h√¨nh: **{type(selected_model).__name__}**")

        if isinstance(selected_model, KMeans):
            st.write("üî¢ S·ªë l∆∞·ª£ng c·ª•m: **{}**".format(selected_model.n_clusters))
            st.write("üî¢ T√¢m c·ª•m (centroids):")
            st.write(selected_model.cluster_centers_)
        elif isinstance(selected_model, DBSCAN):
            num_clusters = len(set(labels)) - (1 if -1 in labels else 0)
            num_noise = np.sum(labels == -1)
            st.write(f"üî¢ S·ªë l∆∞·ª£ng c·ª•m: **{num_clusters}**")
            st.write(f"üî¢ S·ªë l∆∞·ª£ng ƒëi·ªÉm nhi·ªÖu (noise): **{num_noise}**")

        # Ho√†n th√†nh
        status_text.text("‚úÖ Ho√†n th√†nh tr·ª±c quan h√≥a!")
        progress_bar.progress(100)
def show_experiment_selector():
    st.title("üìä MLflow Experiments")

    experiment_name = "Clustering"
    
    # L·∫•y danh s√°ch experiment
    experiments = mlflow.search_experiments()
    selected_experiment = next((exp for exp in experiments if exp.name == experiment_name), None)

    if not selected_experiment:
        st.error(f"‚ùå Experiment '{experiment_name}' kh√¥ng t·ªìn t·∫°i!")
        return

    st.subheader(f"üìå Experiment: {experiment_name}")
    st.write(f"**Experiment ID:** {selected_experiment.experiment_id}")
    st.write(f"**Tr·∫°ng th√°i:** {'Active' if selected_experiment.lifecycle_stage == 'active' else 'Deleted'}")
    st.write(f"**V·ªã tr√≠ l∆∞u tr·ªØ:** {selected_experiment.artifact_location}")

    # L·∫•y danh s√°ch runs trong experiment
    runs = mlflow.search_runs(experiment_ids=[selected_experiment.experiment_id])

    if runs.empty:
        st.warning("‚ö† Kh√¥ng c√≥ runs n√†o trong experiment n√†y.")
        return

    st.write("### üèÉ‚Äç‚ôÇÔ∏è C√°c Runs g·∫ßn ƒë√¢y:")

    # T·∫°o danh s√°ch run name v√† map v·ªõi run_id
    run_dict = {}
    for _, run in runs.iterrows():
        run_name = run.get("tags.mlflow.runName", f"Run {run['run_id'][:8]}")
        run_dict[run_name] = run["run_id"]  # Map run_name -> run_id

    # Ch·ªçn run theo t√™n
    selected_run_name = st.selectbox("üîç Ch·ªçn m·ªôt run:", list(run_dict.keys()),key="run_selector_selectbox" )
    selected_run_id = run_dict[selected_run_name]

    # L·∫•y th√¥ng tin c·ªßa run ƒë√£ ch·ªçn
    selected_run = mlflow.get_run(selected_run_id)

    if selected_run:
        st.subheader(f"üìå Th√¥ng tin Run: {selected_run_name}")
        st.write(f"**Run ID:** {selected_run_id}")
        st.write(f"**Tr·∫°ng th√°i:** {selected_run.info.status}")
        
        start_time_ms = selected_run.info.start_time
        start_time = datetime.fromtimestamp(start_time_ms / 1000).strftime("%Y-%m-%d %H:%M:%S") if start_time_ms else "Kh√¥ng c√≥ th√¥ng tin"

        st.write(f"**Th·ªùi gian ch·∫°y:** {start_time}")

        params = selected_run.data.params
        metrics = selected_run.data.metrics

        if params:
            st.write("### ‚öôÔ∏è Parameters:")
            st.json(params)

        if metrics:
            st.write("### üìä Metrics:")
            st.json(metrics)

    else:
        st.warning("‚ö† Kh√¥ng t√¨m th·∫•y th√¥ng tin cho run n√†y.")


def Clustering():
    st.title("üñäÔ∏è MNIST Clustering App")

    tab1, tab2, tab3, tab4 = st.tabs(["üìò Data", "‚öôÔ∏è Hu·∫•n luy·ªán", "üî¢ Tr·ª±c quan h√≥a", "üî•Mlflow"])

    with tab1:
        data()
        
    with tab2:
        split_data()
        train()
        
    with tab3:
        visualize_clusters()   
    with tab4:
        show_experiment_selector()  

if __name__ == "__main__":
    Clustering()