import streamlit as st
import numpy as np
from sklearn.model_selection import train_test_split
from PIL import Image, ImageOps
import os
import mlflow
from datetime import datetime
from sklearn.datasets import fetch_openml
from sklearn.cluster import KMeans, DBSCAN
from sklearn.metrics import silhouette_score

def load_mnist():
    X = np.load("data/mnist/X.npy")
    return X

def data():
    st.header("MNIST Dataset")
    st.write("""
      **MNIST** lÃ  má»™t trong nhá»¯ng bá»™ dá»¯ liá»‡u ná»•i tiáº¿ng vÃ  phá»• biáº¿n nháº¥t trong cá»™ng Ä‘á»“ng há»c mÃ¡y, 
      Ä‘áº·c biá»‡t lÃ  trong cÃ¡c nghiÃªn cá»©u vá» nháº­n diá»‡n máº«u vÃ  phÃ¢n loáº¡i hÃ¬nh áº£nh.
  
      - Bá»™ dá»¯ liá»‡u bao gá»“m tá»•ng cá»™ng **70.000 áº£nh chá»¯ sá»‘ viáº¿t tay** tá»« **0** Ä‘áº¿n **9**, 
        má»—i áº£nh cÃ³ kÃ­ch thÆ°á»›c **28 x 28 pixel**.
      - Chia thÃ nh:
        - **Training set**: 60.000 áº£nh Ä‘á»ƒ huáº¥n luyá»‡n.
        - **Test set**: 10.000 áº£nh Ä‘á»ƒ kiá»ƒm tra.
      - Má»—i hÃ¬nh áº£nh lÃ  má»™t chá»¯ sá»‘ viáº¿t tay, Ä‘Æ°á»£c chuáº©n hÃ³a vÃ  chuyá»ƒn thÃ nh dáº¡ng grayscale (Ä‘en tráº¯ng).
  
      Dá»¯ liá»‡u nÃ y Ä‘Æ°á»£c sá»­ dá»¥ng rá»™ng rÃ£i Ä‘á»ƒ xÃ¢y dá»±ng cÃ¡c mÃ´ hÃ¬nh nháº­n diá»‡n chá»¯ sá»‘.
      """)

    st.subheader("Má»™t sá»‘ hÃ¬nh áº£nh tá»« MNIST Dataset")
    st.image("mnit.png", caption="Má»™t sá»‘ hÃ¬nh áº£nh tá»« MNIST Dataset", use_container_width=True)

    st.subheader("á»¨ng dá»¥ng thá»±c táº¿ cá»§a MNIST")
    st.write("""
      Bá»™ dá»¯ liá»‡u MNIST Ä‘Ã£ Ä‘Æ°á»£c sá»­ dá»¥ng trong nhiá»u á»©ng dá»¥ng nháº­n dáº¡ng chá»¯ sá»‘ viáº¿t tay, cháº³ng háº¡n nhÆ°:
      - Nháº­n diá»‡n sá»‘ trÃªn cÃ¡c hoÃ¡ Ä‘Æ¡n thanh toÃ¡n, biÃªn lai cá»­a hÃ ng.
      - Xá»­ lÃ½ chá»¯ sá»‘ trÃªn cÃ¡c bÆ°u kiá»‡n gá»­i qua bÆ°u Ä‘iá»‡n.
      - á»¨ng dá»¥ng trong cÃ¡c há»‡ thá»‘ng nháº­n diá»‡n tÃ i liá»‡u tá»± Ä‘á»™ng.
    """)

    st.subheader("VÃ­ dá»¥ vá» cÃ¡c mÃ´ hÃ¬nh há»c mÃ¡y vá»›i MNIST")
    st.write("""
      CÃ¡c mÃ´ hÃ¬nh há»c mÃ¡y phá»• biáº¿n Ä‘Ã£ Ä‘Æ°á»£c huáº¥n luyá»‡n vá»›i bá»™ dá»¯ liá»‡u MNIST bao gá»“m:
      - **Logistic Regression**
      - **Decision Trees**
      - **K-Nearest Neighbors (KNN)**
      - **Support Vector Machines (SVM)**
      - **Convolutional Neural Networks (CNNs)**
    """)




from sklearn.metrics.pairwise import euclidean_distances
import numpy as np

def split_data():
    st.title("ğŸ“Œ Chia dá»¯ liá»‡u (Unsupervised Learning)")

    # Táº£i dá»¯ liá»‡u MNIST
    X = load_mnist()
    total_samples = X.shape[0]
    if "clustering_split_done" not in st.session_state:
        st.session_state.clustering_split_done = False

    # Khá»Ÿi táº¡o cÃ¡c thuá»™c tÃ­nh trong session_state náº¿u chÆ°a tá»“n táº¡i
    if "test_size" not in st.session_state:
        st.session_state.test_size = 0.1  # GiÃ¡ trá»‹ máº·c Ä‘á»‹nh
    if "train_size" not in st.session_state:
        st.session_state.train_size = 0
    if "total_samples" not in st.session_state:
        st.session_state.total_samples = total_samples

    # Thanh kÃ©o chá»n sá»‘ lÆ°á»£ng áº£nh Ä‘á»ƒ sá»­ dá»¥ng
    num_samples = st.number_input("ğŸ“Œ Nháº­p sá»‘ lÆ°á»£ng áº£nh Ä‘á»ƒ train:", min_value=1000, max_value=70000, value=20000, step=1000)



    if st.button("âœ… XÃ¡c nháº­n & LÆ°u", key="split_data_confirm_button"):
        st.session_state.clustering_split_done = True  # ÄÃ¡nh dáº¥u Ä‘Ã£ chia dá»¯ liá»‡u
        st.success("âœ… Dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c chia thÃ nh cÃ´ng!")

        st.session_state.train_size = num_samples

        # Chá»n sá»‘ lÆ°á»£ng áº£nh mong muá»‘n
        X_selected = X[:num_samples]

        # Chia train/test (náº¿u test_size > 0)
        # Náº¿u khÃ´ng chia test, sá»­ dá»¥ng toÃ n bá»™ dá»¯ liá»‡u
        st.session_state["clustering_X_train"] = X_selected
        st.session_state["clustering_X_test"] = np.array([])  # KhÃ´ng cÃ³ táº­p test
        st.success(f"ğŸ”¹ Dá»¯ liá»‡u Ä‘Ã£ sáºµn sÃ ng: {len(X_selected)} áº£nh")

    if "X_train" in st.session_state:
        st.write("ğŸ“Œ Dá»¯ liá»‡u Ä‘Ã£ sáºµn sÃ ng Ä‘á»ƒ sá»­ dá»¥ng!")



def mlflow_input():
    DAGSHUB_MLFLOW_URI = "https://dagshub.com/NewbieHocIT/MocMayvsPython.mlflow"
    st.session_state['mlflow_url'] = DAGSHUB_MLFLOW_URI
    mlflow.set_tracking_uri(DAGSHUB_MLFLOW_URI)

    os.environ["MLFLOW_TRACKING_USERNAME"] = "NewbieHocIT"
    os.environ["MLFLOW_TRACKING_PASSWORD"] = "681dda9a41f9271a144aa94fa8624153a3c95696"

    mlflow.set_experiment("Clustering")


def train():
    mlflow_input()

    # Kiá»ƒm tra dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c chia chÆ°a
    if "clustering_X_train" not in st.session_state or "clustering_X_test" not in st.session_state:
        st.error("âš ï¸ ChÆ°a cÃ³ dá»¯ liá»‡u! HÃ£y chia dá»¯ liá»‡u trÆ°á»›c.")
        return

    X_train = st.session_state["clustering_X_train"]
    X_test = st.session_state["clustering_X_test"]

    # Chuáº©n hÃ³a dá»¯ liá»‡u
    X_train = X_train.reshape(-1, 28 * 28) / 255.0
    X_test = X_test.reshape(-1, 28 * 28) / 255.0 if X_test.size > 0 else None

    st.header("âš™ï¸ Chá»n mÃ´ hÃ¬nh & Huáº¥n luyá»‡n")

    model_choice = st.selectbox("Chá»n mÃ´ hÃ¬nh:", ["K-means", "DBSCAN"], key="clustering_model_choice_selectbox")

    if model_choice == "K-means":
        n_clusters = st.slider("n_clusters", 2, 20, 10, key="clustering_n_clusters_slider")
        model = KMeans(n_clusters=n_clusters)
    elif model_choice == "DBSCAN":
        # Tham sá»‘ máº·c Ä‘á»‹nh tá»‘t hÆ¡n cho DBSCAN vá»›i MNIST
        eps = st.slider("eps (Khoáº£ng cÃ¡ch tá»‘i Ä‘a giá»¯a hai Ä‘iá»ƒm Ä‘á»ƒ coi lÃ  lÃ¢n cáº­n)", 0.1, 10.0, 4.2, step=0.1, key="clustering_eps_slider")
        min_samples = st.slider("min_samples (Sá»‘ lÆ°á»£ng Ä‘iá»ƒm tá»‘i thiá»ƒu trong má»™t lÃ¢n cáº­n)", 2, 50, 10, key="clustering_min_samples_slider")
        model = DBSCAN(eps=eps, min_samples=min_samples)

    run_name = st.text_input("ğŸ”¹ Nháº­p tÃªn Run:", "Default_Run", key="clustering_run_name_input")
    st.session_state["run_name"] = run_name if run_name else "default_run"

    if st.button("Huáº¥n luyá»‡n mÃ´ hÃ¬nh", key="clustering_train_button"):
        with mlflow.start_run(run_name=f"Train_{st.session_state['run_name']}"):
            # CÃ¡c bÆ°á»›c log param nhÆ° cÅ©
            mlflow.log_param("test_size", st.session_state.test_size)
            mlflow.log_param("train_size", st.session_state.train_size)
            mlflow.log_param("num_samples", st.session_state.total_samples)

            progress_bar = st.progress(0)
            status_text = st.empty()



    # Huáº¥n luyá»‡n mÃ´ hÃ¬nh
            status_text.text("â³ Äang huáº¥n luyá»‡n mÃ´ hÃ¬nh...")
            start_time = time.time()
            model.fit(X_train)
            training_time = time.time() - start_time
            labels = model.labels_ if hasattr(model, "labels_") else model.predict(X_train)
            st.session_state["clustering_labels"] = labels

            # Giáº£ láº­p thanh tiáº¿n trÃ¬nh mÆ°á»£t mÃ 
            total_steps = 100
            for i in range(total_steps + 1):
                progress = min(i / total_steps, 0.5)  # 0% -> 50% cho huáº¥n luyá»‡n
                progress_bar.progress(progress)
                time.sleep(training_time / (2 * total_steps))  # Äiá»u chá»‰nh tá»‘c Ä‘á»™ dá»±a trÃªn thá»i gian thá»±c

            # TÃ­nh silhouette score
            status_text.text("ğŸ“Š Äang tÃ­nh toÃ¡n silhouette score...")
            if len(np.unique(labels)) > 1 and -1 not in labels:
                silhouette_avg = silhouette_score(X_train, labels)
                st.success(f"ğŸ“Š **Silhouette Score**: {silhouette_avg:.4f}")
                mlflow.log_metric("silhouette_score", silhouette_avg)
            # Tiáº¿p tá»¥c tÄƒng progress tá»« 50% Ä‘áº¿n 80%
            for i in range(total_steps // 2, int(total_steps * 0.8)):
                progress = i / total_steps
                progress_bar.progress(progress)
                time.sleep(0.01)

            # Logging MLflow vÃ  lÆ°u mÃ´ hÃ¬nh
            status_text.text("ğŸ“ Äang ghi log vÃ o MLflow...")
            mlflow.log_param("model", model_choice)
            if model_choice == "K-means":
                mlflow.log_param("n_clusters", n_clusters)
            elif model_choice == "DBSCAN":
                mlflow.log_param("eps", eps)
                mlflow.log_param("min_samples", min_samples)
            mlflow.sklearn.log_model(model, model_choice.lower())

            # Tiáº¿n trÃ¬nh tá»« 80% Ä‘áº¿n 100%
            status_text.text("ğŸ’¾ Äang lÆ°u mÃ´ hÃ¬nh...")
            for i in range(int(total_steps * 0.8), total_steps + 1):
                progress = i / total_steps
                progress_bar.progress(progress)
                time.sleep(0.01)

            if "clustering_models" not in st.session_state:
                st.session_state["clustering_models"] = []

            model_name = model_choice.lower().replace(" ", "_")
            if model_choice == "DBSCAN":
                model_name += f"_eps{eps}_min_samples{min_samples}"
            elif model_choice == "K-means":
                model_name += f"_n_clusters{n_clusters}"

            existing_model = next((item for item in st.session_state["clustering_models"] if item["name"] == model_name), None)

            if existing_model:
                count = 1
                new_model_name = f"{model_name}_{count}"
                while any(item["name"] == new_model_name for item in st.session_state["clustering_models"]):
                    count += 1
                    new_model_name = f"{model_name}_{count}"
                model_name = new_model_name
                st.warning(f"âš ï¸ MÃ´ hÃ¬nh Ä‘Æ°á»£c lÆ°u vá»›i tÃªn: {model_name}")

            st.session_state["clustering_models"].append({"name": model_name, "model": model})

            # Hiá»ƒn thá»‹ thÃ´ng tin bá»• sung cho DBSCAN
            if model_choice == "DBSCAN":
                num_clusters = len(set(labels)) - (1 if -1 in labels else 0)
                num_noise = list(labels).count(-1)
                st.write(f"ğŸ”¢ Sá»‘ lÆ°á»£ng cá»¥m: {num_clusters}")
                st.write(f"ğŸ”¢ Sá»‘ lÆ°á»£ng Ä‘iá»ƒm nhiá»…u: {num_noise}")

            # Hiá»ƒn thá»‹ silhouette score (náº¿u Ä‘Ã£ tÃ­nh)
            if "silhouette_avg" in locals() and len(np.unique(labels)) > 1 and -1 not in labels:
                st.write(f"ğŸ“Š **Silhouette Score**: {silhouette_avg:.4f}")
            elif model_choice == "DBSCAN" and -1 in labels:
                # TÃ­nh silhouette score loáº¡i bá» nhiá»…u cho DBSCAN
                if num_clusters > 1:  # Chá»‰ tÃ­nh náº¿u cÃ³ hÆ¡n 1 cá»¥m há»£p lá»‡
                    mask = labels != -1  # Lá»c bá» cÃ¡c Ä‘iá»ƒm nhiá»…u
                    if mask.sum() > 0:  # Äáº£m báº£o cÃ²n dá»¯ liá»‡u sau khi lá»c
                        silhouette_avg_no_noise = silhouette_score(X_train[mask], labels[mask])
                        st.write(f"ğŸ“Š **Silhouette Score**: {silhouette_avg_no_noise:.4f}")
                    else:
                        st.write("ğŸ“Š KhÃ´ng thá»ƒ tÃ­nh Silhouette Score: KhÃ´ng Ä‘á»§ Ä‘iá»ƒm dá»¯ liá»‡u sau khi loáº¡i bá» nhiá»…u.")
                else:
                    st.write("ğŸ“Š KhÃ´ng thá»ƒ tÃ­nh Silhouette Score: Chá»‰ cÃ³ 1 cá»¥m hoáº·c toÃ n bá»™ lÃ  nhiá»…u.")
            else:
                st.write("ğŸ“Š KhÃ´ng thá»ƒ tÃ­nh Silhouette Score: Chá»‰ cÃ³ 1 cá»¥m.")

            st.write(f"ğŸ”¹ MÃ´ hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c lÆ°u vá»›i tÃªn: {model_name}")
            st.write(f"Tá»•ng sá»‘ mÃ´ hÃ¬nh hiá»‡n táº¡i: {len(st.session_state['clustering_models'])}")

            st.write("ğŸ“‹ Danh sÃ¡ch cÃ¡c mÃ´ hÃ¬nh Ä‘Ã£ lÆ°u:")
            model_names = [model["name"] for model in st.session_state["clustering_models"]]
            st.write(", ".join(model_names))

            st.success(f"âœ… ÄÃ£ log dá»¯ liá»‡u cho **Train_{st.session_state['run_name']}**!")
            status_text.text("ğŸ’¾ ÄÃ£ lÆ°u")
            progress_bar.progress(100)
            
import streamlit as st
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
from sklearn.cluster import KMeans, DBSCAN
import plotly.express as px

import time  # ThÃªm thÆ° viá»‡n time Ä‘á»ƒ mÃ´ phá»ng tiáº¿n trÃ¬nh

import plotly.express as px
from sklearn.decomposition import PCA
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import streamlit as st
from sklearn.cluster import KMeans, DBSCAN
import time

def visualize_clusters():
    st.title("ğŸ”¢ Trá»±c quan hÃ³a cÃ¡c cá»¥m tá»« mÃ´ hÃ¬nh Ä‘Ã£ huáº¥n luyá»‡n")

    # Kiá»ƒm tra mÃ´ hÃ¬nh Ä‘Ã£ huáº¥n luyá»‡n
    if "clustering_models" not in st.session_state or not st.session_state["clustering_models"]:
        st.error("âš ï¸ ChÆ°a cÃ³ mÃ´ hÃ¬nh nÃ o Ä‘Æ°á»£c huáº¥n luyá»‡n. HÃ£y huáº¥n luyá»‡n mÃ´ hÃ¬nh trÆ°á»›c.")
        return

    # Chá»n mÃ´ hÃ¬nh
    model_names = [model["name"] for model in st.session_state["clustering_models"]]
    selected_model_name = st.selectbox("ğŸ” Chá»n mÃ´ hÃ¬nh Ä‘Ã£ huáº¥n luyá»‡n:", model_names)
    selected_model = next(model["model"] for model in st.session_state["clustering_models"] if model["name"] == selected_model_name)

    # Kiá»ƒm tra náº¿u Ä‘Ã£ cÃ³ nhÃ£n cá»¥m tá»« quÃ¡ trÃ¬nh huáº¥n luyá»‡n
    if "clustering_labels" not in st.session_state:
        st.error("âš ï¸ ChÆ°a cÃ³ nhÃ£n cá»¥m Ä‘Æ°á»£c lÆ°u. HÃ£y Ä‘áº£m báº£o mÃ´ hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c huáº¥n luyá»‡n vÃ  lÆ°u nhÃ£n.")
        return
    
    labels = st.session_state["clustering_labels"]

    # Chá»n kiá»ƒu trá»±c quan
    plot_type = st.radio("Chá»n kiá»ƒu trá»±c quan:", ["2D", "3D"])

    # NÃºt báº¯t Ä‘áº§u trá»±c quan hÃ³a
    if st.button("Báº¯t Ä‘áº§u trá»±c quan hÃ³a"):
        # Khá»Ÿi táº¡o thanh tiáº¿n trÃ¬nh vÃ  tráº¡ng thÃ¡i
        progress_bar = st.progress(0)
        status_text = st.empty()

        # BÆ°á»›c 1: Giáº£m chiá»u dá»¯ liá»‡u báº±ng PCA
        status_text.text("â³ Äang giáº£m chiá»u dá»¯ liá»‡u...")
        for percent_complete in range(20):  # TÄƒng dáº§n tá»« 0% Ä‘áº¿n 20%
            time.sleep(0.05)
            progress_bar.progress(percent_complete + 1)

        # Láº¥y dá»¯ liá»‡u tá»« session_state
        X_train = st.session_state["clustering_X_train"]
        X_train = X_train.reshape(-1, 28 * 28) / 255.0

        # Giáº£m chiá»u xuá»‘ng 3D báº±ng PCA
        reducer = PCA(n_components=3, random_state=42)
        X_reduced = reducer.fit_transform(X_train)

        # BÆ°á»›c 2: Chuáº©n bá»‹ dá»¯ liá»‡u
        status_text.text("â³ Äang chuáº©n bá»‹ dá»¯ liá»‡u Ä‘á»ƒ váº½ biá»ƒu Ä‘á»“...")
        for percent_complete in range(20, 50):  # TÄƒng dáº§n tá»« 20% Ä‘áº¿n 50%
            time.sleep(0.05)
            progress_bar.progress(percent_complete + 1)

        # Táº£i nhÃ£n gá»‘c tá»« MNIST (giáº£ Ä‘á»‹nh báº¡n cÃ³ hÃ m load_mnist tráº£ vá» X vÃ  y)
        from sklearn.datasets import fetch_openml
        X_mnist, y_mnist = fetch_openml('mnist_784', version=1, return_X_y=True, as_frame=False)
        y_mnist = y_mnist[:len(X_train)].astype(int)  # Chá»‰ láº¥y sá»‘ lÆ°á»£ng tÆ°Æ¡ng á»©ng vá»›i X_train

        # Chuyá»ƒn thÃ nh DataFrame
        df = pd.DataFrame(X_reduced, columns=['X1', 'X2', 'X3'])
        df['Cluster'] = labels.astype(str)  # Chuyá»ƒn nhÃ£n cá»¥m thÃ nh chuá»—i Ä‘á»ƒ Plotly coi lÃ  phÃ¢n loáº¡i
        df['Original_Label'] = y_mnist  # NhÃ£n gá»‘c tá»« MNIST

        # BÆ°á»›c 3: Váº½ biá»ƒu Ä‘á»“
        status_text.text("â³ Äang váº½ biá»ƒu Ä‘á»“...")
        for percent_complete in range(50, 90):  # TÄƒng dáº§n tá»« 50% Ä‘áº¿n 90%
            time.sleep(0.05)
            progress_bar.progress(percent_complete + 1)

        if plot_type == "2D":
            plt.figure(figsize=(10, 8))
            sns.scatterplot(x='X1', y='X2', hue='Cluster', data=df, palette='tab10', legend='full')
            plt.xlabel("X1")
            plt.ylabel("X2")
            plt.title("Trá»±c quan hÃ³a cá»¥m báº±ng PCA (2D)")
            st.pyplot(plt)
        else:
            # TÃ¹y chá»‰nh biá»ƒu Ä‘á»“ 3D vá»›i mÃ u riÃªng biá»‡t cho tá»«ng cá»¥m
            fig = px.scatter_3d(
                df, 
                x='X1', 
                y='X2', 
                z='X3', 
                color='Cluster',  # MÃ u theo cá»¥m (phÃ¢n loáº¡i)
                title="Trá»±c quan hÃ³a cá»¥m báº±ng PCA (3D)",
                hover_data={'Original_Label': True, 'Cluster': True},  # Hiá»ƒn thá»‹ nhÃ£n gá»‘c vÃ  nhÃ£n dá»± Ä‘oÃ¡n khi hover
                opacity=0.7,  # Äá»™ trong suá»‘t Ä‘á»ƒ dá»… nhÃ¬n
                symbol='Cluster',  # DÃ¹ng biá»ƒu tÆ°á»£ng khÃ¡c nhau cho tá»«ng cá»¥m (tÃ¹y chá»n)
            )
            # TÃ¹y chá»‰nh giao diá»‡n
            fig.update_traces(marker=dict(size=5))  # KÃ­ch thÆ°á»›c Ä‘iá»ƒm
            fig.update_layout(
                scene=dict(
                    xaxis_title='X1',
                    yaxis_title='X2',
                    zaxis_title='X3',
                    bgcolor='rgba(0,0,0,0)',  # Ná»n trong suá»‘t
                ),
                margin=dict(l=0, r=0, b=0, t=40),  # Giáº£m lá»
                title_x=0.5,  # CÄƒn giá»¯a tiÃªu Ä‘á»
                legend_title_text='Cá»¥m',  # TiÃªu Ä‘á» legend
                coloraxis_showscale=False,  # áº¨n thanh mÃ u gradient
            )
            st.plotly_chart(fig, use_container_width=True)

        # BÆ°á»›c 4: Hiá»ƒn thá»‹ thÃ´ng tin mÃ´ hÃ¬nh
        status_text.text("â³ Äang hiá»ƒn thá»‹ thÃ´ng tin mÃ´ hÃ¬nh...")
        for percent_complete in range(90, 100):  # TÄƒng dáº§n tá»« 90% Ä‘áº¿n 100%
            time.sleep(0.05)
            progress_bar.progress(percent_complete + 1)

        # Hiá»ƒn thá»‹ thÃ´ng tin mÃ´ hÃ¬nh
        st.write("ğŸ“‹ **ThÃ´ng tin mÃ´ hÃ¬nh:**")
        st.write(f"- TÃªn mÃ´ hÃ¬nh: **{selected_model_name}**")
        st.write(f"- Loáº¡i mÃ´ hÃ¬nh: **{type(selected_model).__name__}**")

        if isinstance(selected_model, KMeans):
            st.write("ğŸ”¢ Sá»‘ lÆ°á»£ng cá»¥m: **{}**".format(selected_model.n_clusters))
            st.write("ğŸ”¢ TÃ¢m cá»¥m (centroids):")
            st.write(selected_model.cluster_centers_)
        elif isinstance(selected_model, DBSCAN):
            num_clusters = len(set(labels)) - (1 if -1 in labels else 0)
            num_noise = np.sum(labels == -1)
            st.write(f"ğŸ”¢ Sá»‘ lÆ°á»£ng cá»¥m: **{num_clusters}**")
            st.write(f"ğŸ”¢ Sá»‘ lÆ°á»£ng Ä‘iá»ƒm nhiá»…u (noise): **{num_noise}**")

        # HoÃ n thÃ nh
        status_text.text("âœ… HoÃ n thÃ nh trá»±c quan hÃ³a!")
        progress_bar.progress(100)
def show_experiment_selector():
    st.title("ğŸ“Š MLflow Experiments")

    experiment_name = "Clustering"
    
    # Láº¥y danh sÃ¡ch experiment
    experiments = mlflow.search_experiments()
    selected_experiment = next((exp for exp in experiments if exp.name == experiment_name), None)

    if not selected_experiment:
        st.error(f"âŒ Experiment '{experiment_name}' khÃ´ng tá»“n táº¡i!")
        return

    st.subheader(f"ğŸ“Œ Experiment: {experiment_name}")
    st.write(f"**Experiment ID:** {selected_experiment.experiment_id}")
    st.write(f"**Tráº¡ng thÃ¡i:** {'Active' if selected_experiment.lifecycle_stage == 'active' else 'Deleted'}")
    st.write(f"**Vá»‹ trÃ­ lÆ°u trá»¯:** {selected_experiment.artifact_location}")

    # Láº¥y danh sÃ¡ch runs trong experiment
    runs = mlflow.search_runs(experiment_ids=[selected_experiment.experiment_id])

    if runs.empty:
        st.warning("âš  KhÃ´ng cÃ³ runs nÃ o trong experiment nÃ y.")
        return

    st.write("### ğŸƒâ€â™‚ï¸ CÃ¡c Runs gáº§n Ä‘Ã¢y:")

    # Táº¡o danh sÃ¡ch run name vÃ  map vá»›i run_id
    run_dict = {}
    for _, run in runs.iterrows():
        run_name = run.get("tags.mlflow.runName", f"Run {run['run_id'][:8]}")
        run_dict[run_name] = run["run_id"]  # Map run_name -> run_id

    # Chá»n run theo tÃªn
    selected_run_name = st.selectbox("ğŸ” Chá»n má»™t run:", list(run_dict.keys()),key="run_selector_selectbox" )
    selected_run_id = run_dict[selected_run_name]

    # Láº¥y thÃ´ng tin cá»§a run Ä‘Ã£ chá»n
    selected_run = mlflow.get_run(selected_run_id)

    if selected_run:
        st.subheader(f"ğŸ“Œ ThÃ´ng tin Run: {selected_run_name}")
        st.write(f"**Run ID:** {selected_run_id}")
        st.write(f"**Tráº¡ng thÃ¡i:** {selected_run.info.status}")
        
        start_time_ms = selected_run.info.start_time
        start_time = datetime.fromtimestamp(start_time_ms / 1000).strftime("%Y-%m-%d %H:%M:%S") if start_time_ms else "KhÃ´ng cÃ³ thÃ´ng tin"

        st.write(f"**Thá»i gian cháº¡y:** {start_time}")

        params = selected_run.data.params
        metrics = selected_run.data.metrics

        if params:
            st.write("### âš™ï¸ Parameters:")
            st.json(params)

        if metrics:
            st.write("### ğŸ“Š Metrics:")
            st.json(metrics)

    else:
        st.warning("âš  KhÃ´ng tÃ¬m tháº¥y thÃ´ng tin cho run nÃ y.")


def Clustering():
    st.title("ğŸ–Šï¸ MNIST Clustering App")

    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“˜ Data", "âš™ï¸ Huáº¥n luyá»‡n", "ğŸ”¢ Trá»±c quan hÃ³a", "ğŸ”¥Mlflow"])

    with tab1:
        data()
        
    with tab2:
        split_data()
        train()
        
    with tab3:
        visualize_clusters()   
    with tab4:
        show_experiment_selector()  

if __name__ == "__main__":
    Clustering()