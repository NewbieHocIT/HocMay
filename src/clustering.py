import streamlit as st
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from PIL import Image, ImageOps
import pandas as pd
import os
import mlflow
from datetime import datetime
from sklearn.datasets import fetch_openml
from sklearn.cluster import KMeans, DBSCAN
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
from sklearn.metrics import silhouette_score
# Load dá»¯ liá»‡u MNIST
def load_mnist():
    mnist = fetch_openml('mnist_784', version=1, as_frame=False)
    X, y = mnist.data, mnist.target.astype(int)
    return X, y

def data():
    st.header("MNIST Dataset")
    st.write("""
      **MNIST** lÃ  má»™t trong nhá»¯ng bá»™ dá»¯ liá»‡u ná»•i tiáº¿ng vÃ  phá»• biáº¿n nháº¥t trong cá»™ng Ä‘á»“ng há»c mÃ¡y, 
      Ä‘áº·c biá»‡t lÃ  trong cÃ¡c nghiÃªn cá»©u vá» nháº­n diá»‡n máº«u vÃ  phÃ¢n loáº¡i hÃ¬nh áº£nh.
  
      - Bá»™ dá»¯ liá»‡u bao gá»“m tá»•ng cá»™ng **70.000 áº£nh chá»¯ sá»‘ viáº¿t tay** tá»« **0** Ä‘áº¿n **9**, 
        má»—i áº£nh cÃ³ kÃ­ch thÆ°á»›c **28 x 28 pixel**.
      - Chia thÃ nh:
        - **Training set**: 60.000 áº£nh Ä‘á»ƒ huáº¥n luyá»‡n.
        - **Test set**: 10.000 áº£nh Ä‘á»ƒ kiá»ƒm tra.
      - Má»—i hÃ¬nh áº£nh lÃ  má»™t chá»¯ sá»‘ viáº¿t tay, Ä‘Æ°á»£c chuáº©n hÃ³a vÃ  chuyá»ƒn thÃ nh dáº¡ng grayscale (Ä‘en tráº¯ng).
  
      Dá»¯ liá»‡u nÃ y Ä‘Æ°á»£c sá»­ dá»¥ng rá»™ng rÃ£i Ä‘á»ƒ xÃ¢y dá»±ng cÃ¡c mÃ´ hÃ¬nh nháº­n diá»‡n chá»¯ sá»‘.
      """)

    st.subheader("Má»™t sá»‘ hÃ¬nh áº£nh tá»« MNIST Dataset")
    st.image("mnit.png", caption="Má»™t sá»‘ hÃ¬nh áº£nh tá»« MNIST Dataset", use_container_width=True)

    st.subheader("á»¨ng dá»¥ng thá»±c táº¿ cá»§a MNIST")
    st.write("""
      Bá»™ dá»¯ liá»‡u MNIST Ä‘Ã£ Ä‘Æ°á»£c sá»­ dá»¥ng trong nhiá»u á»©ng dá»¥ng nháº­n dáº¡ng chá»¯ sá»‘ viáº¿t tay, cháº³ng háº¡n nhÆ°:
      - Nháº­n diá»‡n sá»‘ trÃªn cÃ¡c hoÃ¡ Ä‘Æ¡n thanh toÃ¡n, biÃªn lai cá»­a hÃ ng.
      - Xá»­ lÃ½ chá»¯ sá»‘ trÃªn cÃ¡c bÆ°u kiá»‡n gá»­i qua bÆ°u Ä‘iá»‡n.
      - á»¨ng dá»¥ng trong cÃ¡c há»‡ thá»‘ng nháº­n diá»‡n tÃ i liá»‡u tá»± Ä‘á»™ng.
    """)

    st.subheader("VÃ­ dá»¥ vá» cÃ¡c mÃ´ hÃ¬nh há»c mÃ¡y vá»›i MNIST")
    st.write("""
      CÃ¡c mÃ´ hÃ¬nh há»c mÃ¡y phá»• biáº¿n Ä‘Ã£ Ä‘Æ°á»£c huáº¥n luyá»‡n vá»›i bá»™ dá»¯ liá»‡u MNIST bao gá»“m:
      - **Logistic Regression**
      - **Decision Trees**
      - **K-Nearest Neighbors (KNN)**
      - **Support Vector Machines (SVM)**
      - **Convolutional Neural Networks (CNNs)**
    """)


def reduce_dimensions(X, method='PCA', n_components=2):
    if method == 'PCA':
        reducer = PCA(n_components=n_components)
    elif method == 't-SNE':
        reducer = TSNE(n_components=n_components, perplexity=30, n_iter=300)
    else:
        raise ValueError("PhÆ°Æ¡ng phÃ¡p giáº£m chiá»u khÃ´ng há»£p lá»‡. Chá»n 'PCA' hoáº·c 't-SNE'.")
    
    X_reduced = reducer.fit_transform(X)
    return X_reduced
def split_data():
    st.title("ğŸ“Œ Chia dá»¯ liá»‡u Train/Validation/Test")

    # Táº£i dá»¯ liá»‡u MNIST
    X, y = load_mnist()
    total_samples = X.shape[0]

    num_samples = st.slider(
        "Chá»n sá»‘ lÆ°á»£ng áº£nh Ä‘á»ƒ train (âš ï¸ Sá»‘ lÆ°á»£ng lá»›n sáº½ lÃ¢u hÆ¡n):", 
        1000, total_samples, 10000, 
        key="clustering_num_samples_slider"  # ThÃªm key duy nháº¥t
    )
    st.session_state.total_samples = num_samples

    # Chá»n tá»‰ lá»‡ cho táº­p train vÃ  validation
    train_ratio = st.slider(
        "ğŸ“Œ Chá»n % dá»¯ liá»‡u Train", 
        50, 90, 70, 
        key="clustering_train_ratio_slider"  # ThÃªm key duy nháº¥t
    )
    val_ratio = st.slider(
        "ğŸ“Œ Chá»n % dá»¯ liá»‡u Validation", 
        10, 40, 15, 
        key="clustering_val_ratio_slider"  # ThÃªm key duy nháº¥t
    )
    test_ratio = 100 - train_ratio - val_ratio

    if test_ratio < 10:
        st.warning("âš ï¸ Tá»‰ lá»‡ dá»¯ liá»‡u Test quÃ¡ tháº¥p (dÆ°á»›i 10%). HÃ£y Ä‘iá»u chá»‰nh láº¡i tá»‰ lá»‡ Train vÃ  Validation.")
    else:
        st.write(f"ğŸ“Œ **Tá»· lá»‡ phÃ¢n chia:** Train={train_ratio}%, Validation={val_ratio}%, Test={test_ratio}%")
    
    if st.button("âœ… XÃ¡c nháº­n & LÆ°u", key="clustering_confirm_button"):  # ThÃªm key duy nháº¥t
        X_selected, _, y_selected, _ = train_test_split(X, y, train_size=num_samples, stratify=y, random_state=42)

        stratify_option = y_selected if len(np.unique(y_selected)) > 1 else None
        X_train_full, X_test, y_train_full, y_test = train_test_split(
            X_selected, y_selected, test_size=test_ratio/100, stratify=stratify_option, random_state=42
        )

        stratify_option = y_train_full if len(np.unique(y_train_full)) > 1 else None
        X_train, X_val, y_train, y_val = train_test_split(
            X_train_full, y_train_full, test_size=val_ratio / (train_ratio + val_ratio),
            stratify=stratify_option, random_state=42
        )

        st.session_state.X_train = X_train
        st.session_state.X_val = X_val
        st.session_state.X_test = X_test
        st.session_state.y_train = y_train
        st.session_state.y_val = y_val
        st.session_state.y_test = y_test
        st.session_state.test_size = X_test.shape[0]
        st.session_state.val_size = X_val.shape[0]
        st.session_state.train_size = X_train.shape[0]
    
        summary_df = pd.DataFrame({
            "Táº­p dá»¯ liá»‡u": ["Train", "Validation", "Test"],
            "Sá»‘ lÆ°á»£ng máº«u": [X_train.shape[0], X_val.shape[0], X_test.shape[0]]
        })
        st.success("âœ… Dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c chia thÃ nh cÃ´ng!")
        st.table(summary_df)
        
def mlflow_input():
    DAGSHUB_MLFLOW_URI = "https://dagshub.com/NewbieHocIT/MocMayvsPython.mlflow"
    st.session_state['mlflow_url'] = DAGSHUB_MLFLOW_URI
    mlflow.set_tracking_uri(DAGSHUB_MLFLOW_URI)

    os.environ["MLFLOW_TRACKING_USERNAME"] = "NewbieHocIT"
    os.environ["MLFLOW_TRACKING_PASSWORD"] = "681dda9a41f9271a144aa94fa8624153a3c95696"

    mlflow.set_experiment("Clustering")

def train_model(model, X_train_reduced, y_train, X_test_reduced, y_test, model_choice, reduction_method, n_components, n_clusters=None, eps=None, min_samples=None):
    """
    HÃ m huáº¥n luyá»‡n mÃ´ hÃ¬nh vÃ  log káº¿t quáº£ vÃ o MLflow.
    """
    with mlflow.start_run(run_name=f"Train_{st.session_state['run_name']}"):
        # Log cÃ¡c tham sá»‘
        mlflow.log_param("test_size", st.session_state.test_size)
        mlflow.log_param("val_size", st.session_state.val_size)
        mlflow.log_param("train_size", st.session_state.train_size)
        mlflow.log_param("num_samples", st.session_state.total_samples)
        mlflow.log_param("reduction_method", reduction_method)
        mlflow.log_param("n_components", n_components)

        if model_choice == "K-means":
            mlflow.log_param("n_clusters", n_clusters)
        elif model_choice == "DBSCAN":
            mlflow.log_param("eps", eps)
            mlflow.log_param("min_samples", min_samples)

        st.write("â³ Äang huáº¥n luyá»‡n mÃ´ hÃ¬nh...")
        model.fit(X_train_reduced)
        labels = model.labels_

        # TÃ­nh toÃ¡n silhouette score
        if len(np.unique(labels)) > 1:
            silhouette_avg = silhouette_score(X_train_reduced, labels)
            st.success(f"ğŸ“Š **Silhouette Score**: {silhouette_avg:.4f}")
            mlflow.log_metric("silhouette_score", silhouette_avg)
        else:
            st.warning("âš  KhÃ´ng thá»ƒ tÃ­nh silhouette score vÃ¬ chá»‰ cÃ³ má»™t cá»¥m.")

        # LÆ°u mÃ´ hÃ¬nh vÃ o session_state
        if "models" not in st.session_state:
            st.session_state["models"] = []

        model_name = model_choice.lower().replace(" ", "_")
        if model_choice == "DBSCAN":
            model_name += f"_eps{eps}_min_samples{min_samples}"
        elif model_choice == "K-means":
            model_name += f"_n_clusters{n_clusters}"

        existing_model = next((item for item in st.session_state["models"] if item["name"] == model_name), None)

        if existing_model:
            count = 1
            new_model_name = f"{model_name}_{count}"
            while any(item["name"] == new_model_name for item in st.session_state["models"]):
                count += 1
                new_model_name = f"{model_name}_{count}"
            model_name = new_model_name
            st.warning(f"âš ï¸ MÃ´ hÃ¬nh Ä‘Æ°á»£c lÆ°u vá»›i tÃªn: {model_name}")

        st.session_state["models"].append({"name": model_name, "model": model})
        st.write(f"ğŸ”¹ MÃ´ hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c lÆ°u vá»›i tÃªn: {model_name}")
        st.write(f"Tá»•ng sá»‘ mÃ´ hÃ¬nh hiá»‡n táº¡i: {len(st.session_state['models'])}")

        st.write("ğŸ“‹ Danh sÃ¡ch cÃ¡c mÃ´ hÃ¬nh Ä‘Ã£ lÆ°u:")
        model_names = [model["name"] for model in st.session_state["models"]]
        st.write(", ".join(model_names))

        st.success(f"âœ… ÄÃ£ log dá»¯ liá»‡u cho **Train_{st.session_state['run_name']}**!")
        st.markdown(f"ğŸ”— [Truy cáº­p MLflow UI]({st.session_state['mlflow_url']})")


def train():
    mlflow_input()
    if "X_train" in st.session_state:
        X_train = st.session_state.X_train 
        X_val = st.session_state.X_val 
        X_test = st.session_state.X_test 
        y_train = st.session_state.y_train 
        y_val = st.session_state.y_val 
        y_test = st.session_state.y_test 
    else:
        st.error("âš ï¸ ChÆ°a cÃ³ dá»¯ liá»‡u! HÃ£y chia dá»¯ liá»‡u trÆ°á»›c.")
        return

    X_train = X_train.reshape(-1, 28 * 28) / 255.0
    X_test = X_test.reshape(-1, 28 * 28) / 255.0

    st.header("âš™ï¸ Chá»n mÃ´ hÃ¬nh & Huáº¥n luyá»‡n")

    model_choice = st.selectbox(
        "Chá»n mÃ´ hÃ¬nh:", 
        ["K-means", "DBSCAN"], 
        key="clustering_model_choice_selectbox"  # ThÃªm key duy nháº¥t
    )

    # Giáº£m chiá»u dá»¯ liá»‡u
    reduction_method = st.selectbox(
        "Chá»n phÆ°Æ¡ng phÃ¡p giáº£m chiá»u dá»¯ liá»‡u:", 
        ["PCA", "t-SNE"], 
        key="clustering_reduction_method_selectbox"  # ThÃªm key duy nháº¥t
    )
    n_components = st.slider(
        "Sá»‘ chiá»u sau khi giáº£m:", 
        2, 
        50 if reduction_method == "PCA" else 3,  # Giá»›i háº¡n t-SNE tá»‘i Ä‘a lÃ  3
        2,
        key="clustering_n_components_slider"  # ThÃªm key duy nháº¥t
    )

    # LÆ°u vÃ o session_state
    st.session_state.reduction_method = reduction_method
    st.session_state.n_components = n_components

    X_train_reduced = reduce_dimensions(X_train, method=reduction_method, n_components=n_components)
    X_test_reduced = reduce_dimensions(X_test, method=reduction_method, n_components=n_components)

    if model_choice == "K-means":
        st.markdown("""
        - **K-means** lÃ  má»™t thuáº­t toÃ¡n phÃ¢n cá»¥m dá»±a trÃªn khoáº£ng cÃ¡ch giá»¯a cÃ¡c Ä‘iá»ƒm dá»¯ liá»‡u.
        - **Tham sá»‘ cáº§n chá»n:**  
            - **n_clusters**: Sá»‘ lÆ°á»£ng cá»¥m.  
        """)
        n_clusters = st.slider(
            "n_clusters", 
            2, 20, 10, 
            key="clustering_n_clusters_slider"  # ThÃªm key duy nháº¥t
        )
        model = KMeans(n_clusters=n_clusters)

    elif model_choice == "DBSCAN":
        st.markdown("""
        - **DBSCAN** lÃ  má»™t thuáº­t toÃ¡n phÃ¢n cá»¥m dá»±a trÃªn máº­t Ä‘á»™.
        """)
        eps = st.slider(
            "eps (Khoáº£ng cÃ¡ch tá»‘i Ä‘a giá»¯a hai Ä‘iá»ƒm Ä‘á»ƒ coi lÃ  lÃ¢n cáº­n)", 
            0.1, 1.0, 0.5, 
            key="clustering_eps_slider"  # ThÃªm key duy nháº¥t
        )
        min_samples = st.slider(
            "min_samples (Sá»‘ lÆ°á»£ng Ä‘iá»ƒm tá»‘i thiá»ƒu trong má»™t lÃ¢n cáº­n)", 
            1, 20, 5, 
            key="clustering_min_samples_slider"  # ThÃªm key duy nháº¥t
        )
        model = DBSCAN(eps=eps, min_samples=min_samples)

    if st.button("Huáº¥n luyá»‡n mÃ´ hÃ¬nh", key="clustering_train_button"):  # ThÃªm key duy nháº¥t
        st.session_state["run_name"] = "training_run_1"  # Táº¡o giÃ¡ trá»‹ cho run_name

        # Gá»i hÃ m huáº¥n luyá»‡n mÃ´ hÃ¬nh
        train_model(
            model=model,
            X_train_reduced=X_train_reduced,
            y_train=y_train,
            X_test_reduced=X_test_reduced,
            y_test=y_test,
            model_choice=model_choice,
            reduction_method=reduction_method,
            n_components=n_components,
            n_clusters=n_clusters if model_choice == "K-means" else None,
            eps=eps if model_choice == "DBSCAN" else None,
            min_samples=min_samples if model_choice == "DBSCAN" else None
        )


def du_doan():
    st.title("ğŸ”¢ Dá»± Ä‘oÃ¡n chá»¯ sá»‘ viáº¿t tay")

    if "models" not in st.session_state or not st.session_state["models"]:
        st.error("âš ï¸ ChÆ°a cÃ³ mÃ´ hÃ¬nh nÃ o Ä‘Æ°á»£c huáº¥n luyá»‡n. HÃ£y huáº¥n luyá»‡n mÃ´ hÃ¬nh trÆ°á»›c.")
        return

    model_names = [model["name"] for model in st.session_state["models"]]
    selected_model_name = st.selectbox(
        "ğŸ” Chá»n mÃ´ hÃ¬nh Ä‘Ã£ huáº¥n luyá»‡n:", 
        model_names, 
        key="clustering_model_selectbox"  # ThÃªm key duy nháº¥t
    )
    selected_model = next(model["model"] for model in st.session_state["models"] if model["name"] == selected_model_name)

    uploaded_file = st.file_uploader(
        "ğŸ“¤ Táº£i lÃªn áº£nh chá»¯ sá»‘ viáº¿t tay (28x28 pixel)", 
        type=["png", "jpg", "jpeg"], 
        key="clustering_file_uploader"  # ThÃªm key duy nháº¥t
    )

    if uploaded_file is not None:
        image = Image.open(uploaded_file).convert("L")
        image = ImageOps.invert(image)
        image = image.resize((28, 28))
        st.image(image, caption="áº¢nh Ä‘Ã£ táº£i lÃªn", use_column_width=True)

        img_array = np.array(image).reshape(1, -1) / 255.0
        prediction = selected_model.predict(img_array)
        st.success(f"ğŸ”¢ Dá»± Ä‘oÃ¡n: **{prediction[0]}**")

def show_experiment_selector():
    st.title("ğŸ“Š MLflow Experiments - DAGsHub")

    experiment_name = "Clustering"
    
    experiments = mlflow.search_experiments()
    selected_experiment = next((exp for exp in experiments if exp.name == experiment_name), None)

    if not selected_experiment:
        st.error(f"âŒ Experiment '{experiment_name}' khÃ´ng tá»“n táº¡i!")
        return

    st.subheader(f"ğŸ“Œ Experiment: {experiment_name}")
    st.write(f"**Experiment ID:** {selected_experiment.experiment_id}")
    st.write(f"**Tráº¡ng thÃ¡i:** {'Active' if selected_experiment.lifecycle_stage == 'active' else 'Deleted'}")
    st.write(f"**Vá»‹ trÃ­ lÆ°u trá»¯:** {selected_experiment.artifact_location}")

    runs = mlflow.search_runs(experiment_ids=[selected_experiment.experiment_id])

    if runs.empty:
        st.warning("âš  KhÃ´ng cÃ³ runs nÃ o trong experiment nÃ y.")
        return

    st.write("### ğŸƒâ€â™‚ï¸ CÃ¡c Runs gáº§n Ä‘Ã¢y:")

    run_info = []
    for _, run in runs.iterrows():
        run_id = run["run_id"]
        run_params = mlflow.get_run(run_id).data.params
        run_name = run_params.get("run_name", f"Run {run_id[:8]}")
        run_info.append((run_name, run_id))

    run_name_to_id = dict(run_info)
    run_names = list(run_name_to_id.keys())

    # ThÃªm key duy nháº¥t cho selectbox
    selected_run_name = st.selectbox(
        "ğŸ” Chá»n má»™t run:", 
        run_names, 
        key="clustering_experiment_selectbox"  # ThÃªm key duy nháº¥t
    )
    selected_run_id = run_name_to_id[selected_run_name]

    selected_run = mlflow.get_run(selected_run_id)

    if selected_run:
        st.subheader(f"ğŸ“Œ ThÃ´ng tin Run: {selected_run_name}")
        st.write(f"**Run ID:** {selected_run_id}")
        st.write(f"**Tráº¡ng thÃ¡i:** {selected_run.info.status}")
        start_time_ms = selected_run.info.start_time

        if start_time_ms:
            start_time = datetime.fromtimestamp(start_time_ms / 1000).strftime("%Y-%m-%d %H:%M:%S")
        else:
            start_time = "KhÃ´ng cÃ³ thÃ´ng tin"

        st.write(f"**Thá»i gian cháº¡y:** {start_time}")

        params = selected_run.data.params
        metrics = selected_run.data.metrics

        if params:
            st.write("### âš™ï¸ Parameters:")
            st.json(params)

        if metrics:
            st.write("### ğŸ“Š Metrics:")
            st.json(metrics)

        dataset_path = f"{selected_experiment.artifact_location}/{selected_run_id}/artifacts/dataset.csv"
        st.write("### ğŸ“‚ Dataset:")
        st.write(f"ğŸ“¥ [Táº£i dataset]({dataset_path})")
    else:
        st.warning("âš  KhÃ´ng tÃ¬m tháº¥y thÃ´ng tin cho run nÃ y.")


def Clusterting():
    st.title(" MNIST Clustering App")

    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“˜ Data", "âš™ï¸ Huáº¥n luyá»‡n", "ğŸ”¢ Dá»± Ä‘oÃ¡n", "ğŸ”¥Mlflow"])

    with tab1:
        data()
        
    with tab2:
        split_data()
        train()
        
    with tab3:
        du_doan()   
    with tab4:
        show_experiment_selector()  

if __name__ == "__main__":
    Clusterting()


def data():
    st.header("MNIST Dataset")
    st.write("""
      **MNIST** lÃ  má»™t trong nhá»¯ng bá»™ dá»¯ liá»‡u ná»•i tiáº¿ng vÃ  phá»• biáº¿n nháº¥t trong cá»™ng Ä‘á»“ng há»c mÃ¡y, 
      Ä‘áº·c biá»‡t lÃ  trong cÃ¡c nghiÃªn cá»©u vá» nháº­n diá»‡n máº«u vÃ  phÃ¢n loáº¡i hÃ¬nh áº£nh.
  
      - Bá»™ dá»¯ liá»‡u bao gá»“m tá»•ng cá»™ng **70.000 áº£nh chá»¯ sá»‘ viáº¿t tay** tá»« **0** Ä‘áº¿n **9**, 
        má»—i áº£nh cÃ³ kÃ­ch thÆ°á»›c **28 x 28 pixel**.
      - Chia thÃ nh:
        - **Training set**: 60.000 áº£nh Ä‘á»ƒ huáº¥n luyá»‡n.
        - **Test set**: 10.000 áº£nh Ä‘á»ƒ kiá»ƒm tra.
      - Má»—i hÃ¬nh áº£nh lÃ  má»™t chá»¯ sá»‘ viáº¿t tay, Ä‘Æ°á»£c chuáº©n hÃ³a vÃ  chuyá»ƒn thÃ nh dáº¡ng grayscale (Ä‘en tráº¯ng).
  
      Dá»¯ liá»‡u nÃ y Ä‘Æ°á»£c sá»­ dá»¥ng rá»™ng rÃ£i Ä‘á»ƒ xÃ¢y dá»±ng cÃ¡c mÃ´ hÃ¬nh nháº­n diá»‡n chá»¯ sá»‘.
      """)

    st.subheader("Má»™t sá»‘ hÃ¬nh áº£nh tá»« MNIST Dataset")
    st.image("mnit.png", caption="Má»™t sá»‘ hÃ¬nh áº£nh tá»« MNIST Dataset", use_container_width=True)

    st.subheader("á»¨ng dá»¥ng thá»±c táº¿ cá»§a MNIST")
    st.write("""
      Bá»™ dá»¯ liá»‡u MNIST Ä‘Ã£ Ä‘Æ°á»£c sá»­ dá»¥ng trong nhiá»u á»©ng dá»¥ng nháº­n dáº¡ng chá»¯ sá»‘ viáº¿t tay, cháº³ng háº¡n nhÆ°:
      - Nháº­n diá»‡n sá»‘ trÃªn cÃ¡c hoÃ¡ Ä‘Æ¡n thanh toÃ¡n, biÃªn lai cá»­a hÃ ng.
      - Xá»­ lÃ½ chá»¯ sá»‘ trÃªn cÃ¡c bÆ°u kiá»‡n gá»­i qua bÆ°u Ä‘iá»‡n.
      - á»¨ng dá»¥ng trong cÃ¡c há»‡ thá»‘ng nháº­n diá»‡n tÃ i liá»‡u tá»± Ä‘á»™ng.
    """)

    st.subheader("VÃ­ dá»¥ vá» cÃ¡c mÃ´ hÃ¬nh há»c mÃ¡y vá»›i MNIST")
    st.write("""
      CÃ¡c mÃ´ hÃ¬nh há»c mÃ¡y phá»• biáº¿n Ä‘Ã£ Ä‘Æ°á»£c huáº¥n luyá»‡n vá»›i bá»™ dá»¯ liá»‡u MNIST bao gá»“m:
      - **Logistic Regression**
      - **Decision Trees**
      - **K-Nearest Neighbors (KNN)**
      - **Support Vector Machines (SVM)**
      - **Convolutional Neural Networks (CNNs)**
    """)


def reduce_dimensions(X, method='PCA', n_components=2):
    if method == 'PCA':
        reducer = PCA(n_components=n_components)
    elif method == 't-SNE':
        reducer = TSNE(n_components=n_components, perplexity=30, n_iter=300)
    else:
        raise ValueError("PhÆ°Æ¡ng phÃ¡p giáº£m chiá»u khÃ´ng há»£p lá»‡. Chá»n 'PCA' hoáº·c 't-SNE'.")
    
    X_reduced = reducer.fit_transform(X)
    return X_reduced
def split_data():
    st.title("ğŸ“Œ Chia dá»¯ liá»‡u Train/Validation/Test")

    # Táº£i dá»¯ liá»‡u MNIST
    X, y = load_mnist()
    total_samples = X.shape[0]

    num_samples = st.slider(
        "Chá»n sá»‘ lÆ°á»£ng áº£nh Ä‘á»ƒ train (âš ï¸ Sá»‘ lÆ°á»£ng lá»›n sáº½ lÃ¢u hÆ¡n):", 
        1000, total_samples, 10000, 
        key="clustering_num_samples_slider"  # ThÃªm key duy nháº¥t
    )
    st.session_state.total_samples = num_samples

    # Chá»n tá»‰ lá»‡ cho táº­p train vÃ  validation
    train_ratio = st.slider(
        "ğŸ“Œ Chá»n % dá»¯ liá»‡u Train", 
        50, 90, 70, 
        key="clustering_train_ratio_slider"  # ThÃªm key duy nháº¥t
    )
    val_ratio = st.slider(
        "ğŸ“Œ Chá»n % dá»¯ liá»‡u Validation", 
        10, 40, 15, 
        key="clustering_val_ratio_slider"  # ThÃªm key duy nháº¥t
    )
    test_ratio = 100 - train_ratio - val_ratio

    if test_ratio < 10:
        st.warning("âš ï¸ Tá»‰ lá»‡ dá»¯ liá»‡u Test quÃ¡ tháº¥p (dÆ°á»›i 10%). HÃ£y Ä‘iá»u chá»‰nh láº¡i tá»‰ lá»‡ Train vÃ  Validation.")
    else:
        st.write(f"ğŸ“Œ **Tá»· lá»‡ phÃ¢n chia:** Train={train_ratio}%, Validation={val_ratio}%, Test={test_ratio}%")
    
    if st.button("âœ… XÃ¡c nháº­n & LÆ°u", key="clustering_confirm_button"):  # ThÃªm key duy nháº¥t
        X_selected, _, y_selected, _ = train_test_split(X, y, train_size=num_samples, stratify=y, random_state=42)

        stratify_option = y_selected if len(np.unique(y_selected)) > 1 else None
        X_train_full, X_test, y_train_full, y_test = train_test_split(
            X_selected, y_selected, test_size=test_ratio/100, stratify=stratify_option, random_state=42
        )

        stratify_option = y_train_full if len(np.unique(y_train_full)) > 1 else None
        X_train, X_val, y_train, y_val = train_test_split(
            X_train_full, y_train_full, test_size=val_ratio / (train_ratio + val_ratio),
            stratify=stratify_option, random_state=42
        )

        st.session_state.X_train = X_train
        st.session_state.X_val = X_val
        st.session_state.X_test = X_test
        st.session_state.y_train = y_train
        st.session_state.y_val = y_val
        st.session_state.y_test = y_test
        st.session_state.test_size = X_test.shape[0]
        st.session_state.val_size = X_val.shape[0]
        st.session_state.train_size = X_train.shape[0]
    
        summary_df = pd.DataFrame({
            "Táº­p dá»¯ liá»‡u": ["Train", "Validation", "Test"],
            "Sá»‘ lÆ°á»£ng máº«u": [X_train.shape[0], X_val.shape[0], X_test.shape[0]]
        })
        st.success("âœ… Dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c chia thÃ nh cÃ´ng!")
        st.table(summary_df)
        
def mlflow_input():
    DAGSHUB_MLFLOW_URI = "https://dagshub.com/NewbieHocIT/MocMayvsPython.mlflow"
    st.session_state['mlflow_url'] = DAGSHUB_MLFLOW_URI
    mlflow.set_tracking_uri(DAGSHUB_MLFLOW_URI)

    os.environ["MLFLOW_TRACKING_USERNAME"] = "NewbieHocIT"
    os.environ["MLFLOW_TRACKING_PASSWORD"] = "681dda9a41f9271a144aa94fa8624153a3c95696"

    mlflow.set_experiment("Clustering")

def train_model(model, X_train_reduced, y_train, X_test_reduced, y_test, model_choice, reduction_method, n_components, n_clusters=None, eps=None, min_samples=None):
    """
    HÃ m huáº¥n luyá»‡n mÃ´ hÃ¬nh vÃ  log káº¿t quáº£ vÃ o MLflow.
    """
    with mlflow.start_run(run_name=f"Train_{st.session_state['run_name']}"):
        # Log cÃ¡c tham sá»‘
        mlflow.log_param("test_size", st.session_state.test_size)
        mlflow.log_param("val_size", st.session_state.val_size)
        mlflow.log_param("train_size", st.session_state.train_size)
        mlflow.log_param("num_samples", st.session_state.total_samples)
        mlflow.log_param("reduction_method", reduction_method)
        mlflow.log_param("n_components", n_components)

        if model_choice == "K-means":
            mlflow.log_param("n_clusters", n_clusters)
        elif model_choice == "DBSCAN":
            mlflow.log_param("eps", eps)
            mlflow.log_param("min_samples", min_samples)

        st.write("â³ Äang huáº¥n luyá»‡n mÃ´ hÃ¬nh...")
        model.fit(X_train_reduced)
        labels = model.labels_

        # TÃ­nh toÃ¡n silhouette score
        if len(np.unique(labels)) > 1:
            silhouette_avg = silhouette_score(X_train_reduced, labels)
            st.success(f"ğŸ“Š **Silhouette Score**: {silhouette_avg:.4f}")
            mlflow.log_metric("silhouette_score", silhouette_avg)
        else:
            st.warning("âš  KhÃ´ng thá»ƒ tÃ­nh silhouette score vÃ¬ chá»‰ cÃ³ má»™t cá»¥m.")

        # LÆ°u mÃ´ hÃ¬nh vÃ o session_state
        if "models" not in st.session_state:
            st.session_state["models"] = []

        model_name = model_choice.lower().replace(" ", "_")
        if model_choice == "DBSCAN":
            model_name += f"_eps{eps}_min_samples{min_samples}"
        elif model_choice == "K-means":
            model_name += f"_n_clusters{n_clusters}"

        existing_model = next((item for item in st.session_state["models"] if item["name"] == model_name), None)

        if existing_model:
            count = 1
            new_model_name = f"{model_name}_{count}"
            while any(item["name"] == new_model_name for item in st.session_state["models"]):
                count += 1
                new_model_name = f"{model_name}_{count}"
            model_name = new_model_name
            st.warning(f"âš ï¸ MÃ´ hÃ¬nh Ä‘Æ°á»£c lÆ°u vá»›i tÃªn: {model_name}")

        st.session_state["models"].append({"name": model_name, "model": model})
        st.write(f"ğŸ”¹ MÃ´ hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c lÆ°u vá»›i tÃªn: {model_name}")
        st.write(f"Tá»•ng sá»‘ mÃ´ hÃ¬nh hiá»‡n táº¡i: {len(st.session_state['models'])}")

        st.write("ğŸ“‹ Danh sÃ¡ch cÃ¡c mÃ´ hÃ¬nh Ä‘Ã£ lÆ°u:")
        model_names = [model["name"] for model in st.session_state["models"]]
        st.write(", ".join(model_names))

        st.success(f"âœ… ÄÃ£ log dá»¯ liá»‡u cho **Train_{st.session_state['run_name']}**!")
        st.markdown(f"ğŸ”— [Truy cáº­p MLflow UI]({st.session_state['mlflow_url']})")


def train():
    mlflow_input()
    if "X_train" in st.session_state:
        X_train = st.session_state.X_train 
        X_val = st.session_state.X_val 
        X_test = st.session_state.X_test 
        y_train = st.session_state.y_train 
        y_val = st.session_state.y_val 
        y_test = st.session_state.y_test 
    else:
        st.error("âš ï¸ ChÆ°a cÃ³ dá»¯ liá»‡u! HÃ£y chia dá»¯ liá»‡u trÆ°á»›c.")
        return

    X_train = X_train.reshape(-1, 28 * 28) / 255.0
    X_test = X_test.reshape(-1, 28 * 28) / 255.0

    st.header("âš™ï¸ Chá»n mÃ´ hÃ¬nh & Huáº¥n luyá»‡n")

    model_choice = st.selectbox(
        "Chá»n mÃ´ hÃ¬nh:", 
        ["K-means", "DBSCAN"], 
        key="clustering_model_choice_selectbox"  # ThÃªm key duy nháº¥t
    )

    # Giáº£m chiá»u dá»¯ liá»‡u
    reduction_method = st.selectbox(
        "Chá»n phÆ°Æ¡ng phÃ¡p giáº£m chiá»u dá»¯ liá»‡u:", 
        ["PCA", "t-SNE"], 
        key="clustering_reduction_method_selectbox"  # ThÃªm key duy nháº¥t
    )
    n_components = st.slider(
        "Sá»‘ chiá»u sau khi giáº£m:", 
        2, 
        50 if reduction_method == "PCA" else 3,  # Giá»›i háº¡n t-SNE tá»‘i Ä‘a lÃ  3
        2,
        key="clustering_n_components_slider"  # ThÃªm key duy nháº¥t
    )

    # LÆ°u vÃ o session_state
    st.session_state.reduction_method = reduction_method
    st.session_state.n_components = n_components

    X_train_reduced = reduce_dimensions(X_train, method=reduction_method, n_components=n_components)
    X_test_reduced = reduce_dimensions(X_test, method=reduction_method, n_components=n_components)

    if model_choice == "K-means":
        st.markdown("""
        - **K-means** lÃ  má»™t thuáº­t toÃ¡n phÃ¢n cá»¥m dá»±a trÃªn khoáº£ng cÃ¡ch giá»¯a cÃ¡c Ä‘iá»ƒm dá»¯ liá»‡u.
        - **Tham sá»‘ cáº§n chá»n:**  
            - **n_clusters**: Sá»‘ lÆ°á»£ng cá»¥m.  
        """)
        n_clusters = st.slider(
            "n_clusters", 
            2, 20, 10, 
            key="clustering_n_clusters_slider"  # ThÃªm key duy nháº¥t
        )
        model = KMeans(n_clusters=n_clusters)

    elif model_choice == "DBSCAN":
        st.markdown("""
        - **DBSCAN** lÃ  má»™t thuáº­t toÃ¡n phÃ¢n cá»¥m dá»±a trÃªn máº­t Ä‘á»™.
        """)
        eps = st.slider(
            "eps (Khoáº£ng cÃ¡ch tá»‘i Ä‘a giá»¯a hai Ä‘iá»ƒm Ä‘á»ƒ coi lÃ  lÃ¢n cáº­n)", 
            0.1, 1.0, 0.5, 
            key="clustering_eps_slider"  # ThÃªm key duy nháº¥t
        )
        min_samples = st.slider(
            "min_samples (Sá»‘ lÆ°á»£ng Ä‘iá»ƒm tá»‘i thiá»ƒu trong má»™t lÃ¢n cáº­n)", 
            1, 20, 5, 
            key="clustering_min_samples_slider"  # ThÃªm key duy nháº¥t
        )
        model = DBSCAN(eps=eps, min_samples=min_samples)

    if st.button("Huáº¥n luyá»‡n mÃ´ hÃ¬nh", key="clustering_train_button"):  # ThÃªm key duy nháº¥t
        st.session_state["run_name"] = "training_run_1"  # Táº¡o giÃ¡ trá»‹ cho run_name

        # Gá»i hÃ m huáº¥n luyá»‡n mÃ´ hÃ¬nh
        train_model(
            model=model,
            X_train_reduced=X_train_reduced,
            y_train=y_train,
            X_test_reduced=X_test_reduced,
            y_test=y_test,
            model_choice=model_choice,
            reduction_method=reduction_method,
            n_components=n_components,
            n_clusters=n_clusters if model_choice == "K-means" else None,
            eps=eps if model_choice == "DBSCAN" else None,
            min_samples=min_samples if model_choice == "DBSCAN" else None
        )


def du_doan():
    st.title("ğŸ”¢ Dá»± Ä‘oÃ¡n chá»¯ sá»‘ viáº¿t tay")

    if "models" not in st.session_state or not st.session_state["models"]:
        st.error("âš ï¸ ChÆ°a cÃ³ mÃ´ hÃ¬nh nÃ o Ä‘Æ°á»£c huáº¥n luyá»‡n. HÃ£y huáº¥n luyá»‡n mÃ´ hÃ¬nh trÆ°á»›c.")
        return

    model_names = [model["name"] for model in st.session_state["models"]]
    selected_model_name = st.selectbox(
        "ğŸ” Chá»n mÃ´ hÃ¬nh Ä‘Ã£ huáº¥n luyá»‡n:", 
        model_names, 
        key="clustering_model_selectbox"  # ThÃªm key duy nháº¥t
    )
    selected_model = next(model["model"] for model in st.session_state["models"] if model["name"] == selected_model_name)

    uploaded_file = st.file_uploader(
        "ğŸ“¤ Táº£i lÃªn áº£nh chá»¯ sá»‘ viáº¿t tay (28x28 pixel)", 
        type=["png", "jpg", "jpeg"], 
        key="clustering_file_uploader"  # ThÃªm key duy nháº¥t
    )

    if uploaded_file is not None:
        image = Image.open(uploaded_file).convert("L")
        image = ImageOps.invert(image)
        image = image.resize((28, 28))
        st.image(image, caption="áº¢nh Ä‘Ã£ táº£i lÃªn", use_column_width=True)

        img_array = np.array(image).reshape(1, -1) / 255.0
        prediction = selected_model.predict(img_array)
        st.success(f"ğŸ”¢ Dá»± Ä‘oÃ¡n: **{prediction[0]}**")

def show_experiment_selector():
    st.title("ğŸ“Š MLflow Experiments")

    experiment_name = "Clustering"
    
    experiments = mlflow.search_experiments()
    selected_experiment = next((exp for exp in experiments if exp.name == experiment_name), None)

    if not selected_experiment:
        st.error(f"âŒ Experiment '{experiment_name}' khÃ´ng tá»“n táº¡i!")
        return

    st.subheader(f"ğŸ“Œ Experiment: {experiment_name}")
    st.write(f"**Experiment ID:** {selected_experiment.experiment_id}")
    st.write(f"**Tráº¡ng thÃ¡i:** {'Active' if selected_experiment.lifecycle_stage == 'active' else 'Deleted'}")
    st.write(f"**Vá»‹ trÃ­ lÆ°u trá»¯:** {selected_experiment.artifact_location}")

    runs = mlflow.search_runs(experiment_ids=[selected_experiment.experiment_id])

    if runs.empty:
        st.warning("âš  KhÃ´ng cÃ³ runs nÃ o trong experiment nÃ y.")
        return

    st.write("### ğŸƒâ€â™‚ï¸ CÃ¡c Runs gáº§n Ä‘Ã¢y:")

    run_info = []
    for _, run in runs.iterrows():
        run_id = run["run_id"]
        run_params = mlflow.get_run(run_id).data.params
        run_name = run_params.get("run_name", f"Run {run_id[:8]}")
        run_info.append((run_name, run_id))

    run_name_to_id = dict(run_info)
    run_names = list(run_name_to_id.keys())

    # ThÃªm key duy nháº¥t cho selectbox
    selected_run_name = st.selectbox(
        "ğŸ” Chá»n má»™t run:", 
        run_names, 
        key="clustering_experiment_selectbox"  # ThÃªm key duy nháº¥t
    )
    selected_run_id = run_name_to_id[selected_run_name]

    selected_run = mlflow.get_run(selected_run_id)

    if selected_run:
        st.subheader(f"ğŸ“Œ ThÃ´ng tin Run: {selected_run_name}")
        st.write(f"**Run ID:** {selected_run_id}")
        st.write(f"**Tráº¡ng thÃ¡i:** {selected_run.info.status}")
        start_time_ms = selected_run.info.start_time

        if start_time_ms:
            start_time = datetime.fromtimestamp(start_time_ms / 1000).strftime("%Y-%m-%d %H:%M:%S")
        else:
            start_time = "KhÃ´ng cÃ³ thÃ´ng tin"

        st.write(f"**Thá»i gian cháº¡y:** {start_time}")

        params = selected_run.data.params
        metrics = selected_run.data.metrics

        if params:
            st.write("### âš™ï¸ Parameters:")
            st.json(params)

        if metrics:
            st.write("### ğŸ“Š Metrics:")
            st.json(metrics)

        dataset_path = f"{selected_experiment.artifact_location}/{selected_run_id}/artifacts/dataset.csv"
        st.write("### ğŸ“‚ Dataset:")
        st.write(f"ğŸ“¥ [Táº£i dataset]({dataset_path})")
    else:
        st.warning("âš  KhÃ´ng tÃ¬m tháº¥y thÃ´ng tin cho run nÃ y.")


def Clusterting():
    st.title(" MNIST Clustering App")

    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“˜ Data", "âš™ï¸ Huáº¥n luyá»‡n", "ğŸ”¢ Dá»± Ä‘oÃ¡n", "ğŸ”¥Mlflow"])

    with tab1:
        data()
        
    with tab2:
        split_data()
        train()
        
    with tab3:
        du_doan()   
    with tab4:
        show_experiment_selector()  

if __name__ == "__main__":
    Clusterting()
