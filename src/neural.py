import tensorflow as tf
import tensorflow as tf
Sequential = tf.keras.models.Sequential
Dense = tf.keras.layers.Dense
Dropout = tf.keras.layers.Dropout
Adam = tf.keras.optimizers.Adam


import streamlit as st
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from PIL import Image
import pandas as pd
import os
import mlflow
from datetime import datetime
from sklearn.model_selection import cross_val_score
from streamlit_drawable_canvas import st_canvas


def load_mnist():
    X = np.load("data/mnist/X.npy")
    y = np.load("data/mnist/y.npy")
    return X, y

def data():
    st.header("MNIST Dataset")
    st.write("""
      **MNIST** l√† m·ªôt trong nh·ªØng b·ªô d·ªØ li·ªáu n·ªïi ti·∫øng v√† ph·ªï bi·∫øn nh·∫•t trong c·ªông ƒë·ªìng h·ªçc m√°y, 
      ƒë·∫∑c bi·ªát l√† trong c√°c nghi√™n c·ª©u v·ªÅ nh·∫≠n di·ªán m·∫´u v√† ph√¢n lo·∫°i h√¨nh ·∫£nh.
  
      - B·ªô d·ªØ li·ªáu bao g·ªìm t·ªïng c·ªông **70.000 ·∫£nh ch·ªØ s·ªë vi·∫øt tay** t·ª´ **0** ƒë·∫øn **9**, 
        m·ªói ·∫£nh c√≥ k√≠ch th∆∞·ªõc **28 x 28 pixel**.
      - Chia th√†nh:
        - **Training set**: 60.000 ·∫£nh ƒë·ªÉ hu·∫•n luy·ªán.
        - **Test set**: 10.000 ·∫£nh ƒë·ªÉ ki·ªÉm tra.
      - M·ªói h√¨nh ·∫£nh l√† m·ªôt ch·ªØ s·ªë vi·∫øt tay, ƒë∆∞·ª£c chu·∫©n h√≥a v√† chuy·ªÉn th√†nh d·∫°ng grayscale (ƒëen tr·∫Øng).
  
      D·ªØ li·ªáu n√†y ƒë∆∞·ª£c s·ª≠ d·ª•ng r·ªông r√£i ƒë·ªÉ x√¢y d·ª±ng c√°c m√¥ h√¨nh nh·∫≠n di·ªán ch·ªØ s·ªë.
      """)

    st.subheader("M·ªôt s·ªë h√¨nh ·∫£nh t·ª´ MNIST Dataset")
    st.image("mnit.png", caption="M·ªôt s·ªë h√¨nh ·∫£nh t·ª´ MNIST Dataset", use_container_width=True)

    st.subheader("·ª®ng d·ª•ng th·ª±c t·∫ø c·ªßa MNIST")
    st.write("""
      B·ªô d·ªØ li·ªáu MNIST ƒë√£ ƒë∆∞·ª£c s·ª≠ d·ª•ng trong nhi·ªÅu ·ª©ng d·ª•ng nh·∫≠n d·∫°ng ch·ªØ s·ªë vi·∫øt tay, ch·∫≥ng h·∫°n nh∆∞:
      - Nh·∫≠n di·ªán s·ªë tr√™n c√°c ho√° ƒë∆°n thanh to√°n, bi√™n lai c·ª≠a h√†ng.
      - X·ª≠ l√Ω ch·ªØ s·ªë tr√™n c√°c b∆∞u ki·ªán g·ª≠i qua b∆∞u ƒëi·ªán.
      - ·ª®ng d·ª•ng trong c√°c h·ªá th·ªëng nh·∫≠n di·ªán t√†i li·ªáu t·ª± ƒë·ªông.
    """)

    st.subheader("V√≠ d·ª• v·ªÅ c√°c m√¥ h√¨nh h·ªçc m√°y v·ªõi MNIST")
    st.write("""
      C√°c m√¥ h√¨nh h·ªçc m√°y ph·ªï bi·∫øn ƒë√£ ƒë∆∞·ª£c hu·∫•n luy·ªán v·ªõi b·ªô d·ªØ li·ªáu MNIST bao g·ªìm:
      - **Logistic Regression**
      - **Decision Trees**
      - **K-Nearest Neighbors (KNN)**
      - **Support Vector Machines (SVM)**
      - **Convolutional Neural Networks (CNNs)**
    """)

def split_data():
    st.title("üìå Chia d·ªØ li·ªáu Train/Test")

    # ƒê·ªçc d·ªØ li·ªáu
    X, y = load_mnist() 
    total_samples = X.shape[0]

    # N·∫øu ch∆∞a c√≥ c·ªù "data_split_done", ƒë·∫∑t m·∫∑c ƒë·ªãnh l√† False
    if "data_split_done" not in st.session_state:
        st.session_state.data_split_done = False  

    # Thanh k√©o ch·ªçn s·ªë l∆∞·ª£ng ·∫£nh ƒë·ªÉ train
    num_samples = st.number_input("üìå Nh·∫≠p s·ªë l∆∞·ª£ng ·∫£nh ƒë·ªÉ train:", min_value=1000, max_value=70000, value=20000, step=1000)
    
    # Thanh k√©o ch·ªçn t·ª∑ l·ªá Train/Test
    test_size = st.slider("üìå Ch·ªçn % d·ªØ li·ªáu Test", 10, 50, 20)
    remaining_size = 100 - test_size
    val_size = st.slider("üìå Ch·ªçn % d·ªØ li·ªáu Validation (trong ph·∫ßn Train)", 0, 50, 15)
    st.write(f"üìå **T·ª∑ l·ªá ph√¢n chia:** Test={test_size}%, Validation={val_size}%, Train={remaining_size - val_size}%")

    if st.button("‚úÖ X√°c nh·∫≠n & L∆∞u", key="luu"):
        st.session_state.data_split_done = True  # ƒê√°nh d·∫•u ƒë√£ chia d·ªØ li·ªáu
        
        if num_samples == total_samples:
            X_selected, y_selected = X, y
        else:
            X_selected, _, y_selected, _ = train_test_split(
                X, y, train_size=num_samples, stratify=y, random_state=42
            )

        # Chia train/test
        stratify_option = y_selected if len(np.unique(y_selected)) > 1 else None
        X_train_full, X_test, y_train_full, y_test = train_test_split(
            X_selected, y_selected, test_size=test_size/100, stratify=stratify_option, random_state=42
        )

        # Chia train/val
        if val_size > 0:
            stratify_option = y_train_full if len(np.unique(y_train_full)) > 1 else None
            X_train, X_val, y_train, y_val = train_test_split(
                X_train_full, y_train_full, test_size=val_size / (100 - test_size),
                stratify=stratify_option, random_state=42
            )
        else:
            X_train, y_train = X_train_full, y_train_full
            X_val, y_val = np.array([]), np.array([])  # Validation r·ªóng n·∫øu val_size = 0

        # L∆∞u d·ªØ li·ªáu v√†o session_state
        st.session_state.total_samples = num_samples
        st.session_state["neural_X_train"] = X_train
        st.session_state["neural_X_val"] = X_val
        st.session_state["neural_X_test"] = X_test
        st.session_state["neural_y_train"] = y_train
        st.session_state["neural_y_val"] = y_val
        st.session_state["neural_y_test"] = y_test
        st.session_state.test_size = X_test.shape[0]
        st.session_state.val_size = X_val.shape[0]
        st.session_state.train_size = X_train.shape[0]

        # Hi·ªÉn th·ªã th√¥ng tin chia d·ªØ li·ªáu
        summary_df = pd.DataFrame({
            "T·∫≠p d·ªØ li·ªáu": ["Train", "Validation", "Test"],
            "S·ªë l∆∞·ª£ng m·∫´u": [X_train.shape[0], X_val.shape[0], X_test.shape[0]]
        })
        st.success("‚úÖ D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c chia th√†nh c√¥ng!")
        st.table(summary_df)

    elif st.session_state.data_split_done:
        st.info("‚úÖ D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c chia. Nh·∫•n **üîÑ Chia l·∫°i d·ªØ li·ªáu** ƒë·ªÉ thay ƒë·ªïi.")

def mlflow_input():
    DAGSHUB_MLFLOW_URI = "https://dagshub.com/NewbieHocIT/MocMayvsPython.mlflow"
    st.session_state['mlflow_url'] = DAGSHUB_MLFLOW_URI
    mlflow.set_tracking_uri(DAGSHUB_MLFLOW_URI)

    os.environ["MLFLOW_TRACKING_USERNAME"] = "NewbieHocIT"
    os.environ["MLFLOW_TRACKING_PASSWORD"] = "681dda9a41f9271a144aa94fa8624153a3c95696"

    mlflow.set_experiment("neural")
from tensorflow.python.keras.engine import data_adapter

def _is_distributed_dataset(ds):
    return isinstance(ds, data_adapter.input_lib.DistributedDatasetSpec)

data_adapter._is_distributed_dataset = _is_distributed_dataset

from tensorflow.python.keras.callbacks import Callback

# Callback t√πy ch·ªânh ƒë·ªÉ c·∫≠p nh·∫≠t thanh ti·∫øn tr√¨nh cho hu·∫•n luy·ªán
class ProgressBarCallback(Callback):
    def __init__(self, total_epochs, progress_bar, status_text, max_train_progress=80):
        super(ProgressBarCallback, self).__init__()
        self.total_epochs = total_epochs
        self.progress_bar = progress_bar
        self.status_text = status_text
        self.max_train_progress = max_train_progress  # Gi·ªõi h·∫°n ti·∫øn tr√¨nh hu·∫•n luy·ªán (80%)

    def on_epoch_begin(self, epoch, logs=None):
        progress = (epoch + 1) / self.total_epochs * self.max_train_progress
        self.progress_bar.progress(min(int(progress), self.max_train_progress))
        self.status_text.text(f"üõ†Ô∏è ƒêang hu·∫•n luy·ªán m√¥ h√¨nh... Epoch {epoch + 1}/{self.total_epochs}")

    def on_train_end(self, logs=None):
        self.progress_bar.progress(self.max_train_progress)
        self.status_text.text("‚úÖ Hu·∫•n luy·ªán m√¥ h√¨nh ho√†n t·∫•t, ƒëang chu·∫©n b·ªã logging...")

def train():
    mlflow_input()

    # Ki·ªÉm tra xem d·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c chia ch∆∞a
    if (
        "neural_X_train" not in st.session_state
        or "neural_X_val" not in st.session_state
        or "neural_X_test" not in st.session_state
    ):
        st.error("‚ö†Ô∏è Ch∆∞a c√≥ d·ªØ li·ªáu! H√£y chia d·ªØ li·ªáu tr∆∞·ªõc.")
        return

    # L·∫•y d·ªØ li·ªáu t·ª´ session_state
    X_train = st.session_state["neural_X_train"]
    X_val = st.session_state["neural_X_val"]
    X_test = st.session_state["neural_X_test"]
    y_train = st.session_state["neural_y_train"]
    y_val = st.session_state["neural_y_val"]
    y_test = st.session_state["neural_y_test"]

    # Chuy·ªÉn ƒë·ªïi d·ªØ li·ªáu
    X_train = X_train.reshape(-1, 28 * 28) / 255.0
    X_test = X_test.reshape(-1, 28 * 28) / 255.0
    if X_val.size > 0:
        X_val = X_val.reshape(-1, 28 * 28) / 255.0

    st.header("‚öôÔ∏è Ch·ªçn m√¥ h√¨nh & Hu·∫•n luy·ªán")

    model_choice = st.selectbox(
        "Ch·ªçn m√¥ h√¨nh:", 
        ["Neural Network"], 
        key="neural_model_choice_selectbox"
    )

    if model_choice == "Neural Network":
        st.markdown("""
        - **üß† Neural Network (M·∫°ng n∆°-ron)** l√† m·ªôt m√¥ h√¨nh h·ªçc s√¢u c√≥ kh·∫£ nƒÉng h·ªçc c√°c ƒë·∫∑c tr∆∞ng ph·ª©c t·∫°p t·ª´ d·ªØ li·ªáu.
        - **Tham s·ªë c·∫ßn ch·ªçn:**  
            - **S·ªë l·ªõp ·∫©n**: S·ªë l∆∞·ª£ng l·ªõp ·∫©n trong m·∫°ng.  
            - **S·ªë node m·ªói l·ªõp**: S·ªë l∆∞·ª£ng node trong m·ªói l·ªõp ·∫©n.  
            - **H√†m k√≠ch ho·∫°t**: H√†m k√≠ch ho·∫°t cho c√°c l·ªõp ·∫©n.  
            - **T·ªëc ƒë·ªô h·ªçc**: T·ªëc ƒë·ªô h·ªçc c·ªßa thu·∫≠t to√°n t·ªëi ∆∞u.  
        """)
        
        num_layers = st.slider("S·ªë l·ªõp ·∫©n", 1, 5, 2, key="neural_num_layers_slider")
        num_nodes = st.slider("S·ªë node m·ªói l·ªõp", 32, 256, 128, key="neural_num_nodes_slider")
        activation = st.selectbox("H√†m k√≠ch ho·∫°t", ["relu", "sigmoid", "tanh"], key="neural_activation_selectbox")
        epochs = st.slider("S·ªë epoch", 1, 50, 10, key="neural_epochs_slider")

        # X√¢y d·ª±ng m√¥ h√¨nh
        model = Sequential()
        model.add(Dense(num_nodes, input_shape=(28 * 28,), activation=activation))
        for _ in range(num_layers - 1):
            model.add(Dense(num_nodes, activation=activation))
        model.add(Dense(10, activation='softmax'))
        
        # Bi√™n d·ªãch m√¥ h√¨nh
        model.compile(optimizer=Adam(learning_rate=0.01),
                      loss='sparse_categorical_crossentropy',
                      metrics=['accuracy'])
    
    run_name = st.text_input("üîπ Nh·∫≠p t√™n Run:", "Default_Run", key="neural_run_name_input")
    st.session_state["run_name"] = run_name if run_name else "default_run"
    
    if st.button("Hu·∫•n luy·ªán m√¥ h√¨nh", key="neural_train_button"):
        with mlflow.start_run(run_name=f"Train_{st.session_state['run_name']}"):
            mlflow.log_param("test_size", st.session_state.test_size)
            mlflow.log_param("val_size", st.session_state.val_size)
            mlflow.log_param("train_size", st.session_state.train_size)
            mlflow.log_param("num_samples", st.session_state.total_samples)

            progress_bar = st.progress(0)  # Thanh ti·∫øn tr√¨nh
            status_text = st.empty()  # Hi·ªÉn th·ªã tr·∫°ng th√°i t·ª´ng b∆∞·ªõc

            # Giai ƒëo·∫°n 1: Hu·∫•n luy·ªán (chi·∫øm 80% ti·∫øn tr√¨nh)
            progress_callback = ProgressBarCallback(epochs, progress_bar, status_text, max_train_progress=80)

            if X_val.size > 0:
                history = model.fit(
                    X_train, y_train, 
                    epochs=epochs, 
                    validation_data=(X_val, y_val),
                    callbacks=[progress_callback],
                    verbose=0
                )
            else:
                history = model.fit(
                    X_train, y_train, 
                    epochs=epochs, 
                    callbacks=[progress_callback],
                    verbose=0
                )

            # Giai ƒëo·∫°n 2: Logging v√† ƒë√°nh gi√° (chi·∫øm 20% c√≤n l·∫°i)
            status_text.text("üìä ƒêang ƒë√°nh gi√° m√¥ h√¨nh tr√™n test set...")
            progress_bar.progress(85)  # C·∫≠p nh·∫≠t ti·∫øn tr√¨nh sau khi ƒë√°nh gi√° test set
            test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)

            # Hi·ªÉn th·ªã k·∫øt qu·∫£
            if X_val.size > 0:
                train_accuracy = history.history['accuracy'][-1]
                val_accuracy = history.history['val_accuracy'][-1]
                st.success(f"‚úÖ **ƒê·ªô ch√≠nh x√°c tr√™n t·∫≠p train**: {train_accuracy:.4f}")
                st.success(f"‚úÖ **ƒê·ªô ch√≠nh x√°c tr√™n t·∫≠p validation**: {val_accuracy:.4f}")
            else:
                train_accuracy = history.history['accuracy'][-1]
                st.success(f"‚úÖ **ƒê·ªô ch√≠nh x√°c tr√™n t·∫≠p train**: {train_accuracy:.4f}")
            st.success(f"‚úÖ **ƒê·ªô ch√≠nh x√°c tr√™n test set**: {test_acc:.4f}")

            # Logging v·ªõi MLflow
            status_text.text("üìù ƒêang ghi log v√†o MLflow...")
            progress_bar.progress(90)  # C·∫≠p nh·∫≠t ti·∫øn tr√¨nh khi b·∫Øt ƒë·∫ßu logging

            mlflow.log_param("model", model_choice)
            mlflow.log_param("num_layers", num_layers)
            mlflow.log_param("num_nodes", num_nodes)
            mlflow.log_param("activation", activation)
            mlflow.log_param("learning_rate", 0.01)
            mlflow.log_param("epochs", epochs)

            mlflow.log_metric("test_accuracy", test_acc)
            if X_val.size > 0:
                mlflow.log_metric("train_accuracy", train_accuracy)
                mlflow.log_metric("val_accuracy", val_accuracy)

            # L∆∞u m√¥ h√¨nh
            model_path = f"model_{st.session_state['run_name']}.h5"
            model.save(model_path)
            mlflow.log_artifact(model_path)
            progress_bar.progress(95)  # C·∫≠p nh·∫≠t ti·∫øn tr√¨nh khi l∆∞u m√¥ h√¨nh

            # L∆∞u th√¥ng tin m√¥ h√¨nh v√†o session_state
            if "neural_models" not in st.session_state:
                st.session_state["neural_models"] = []

            model_name = model_choice.lower().replace(" ", "_")
            model_name += f"_{num_layers}layers_{num_nodes}nodes_{activation}"
            existing_model = next((item for item in st.session_state["neural_models"] if item["name"] == model_name), None)

            if existing_model:
                count = 1
                new_model_name = f"{model_name}_{count}"
                while any(item["name"] == new_model_name for item in st.session_state["neural_models"]):
                    count += 1
                    new_model_name = f"{model_name}_{count}"
                model_name = new_model_name
                st.warning(f"‚ö†Ô∏è M√¥ h√¨nh ƒë∆∞·ª£c l∆∞u v·ªõi t√™n: {model_name}")

            st.session_state["neural_models"].append({"name": model_name, "model": model})
            st.write(f"üîπ M√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c l∆∞u v·ªõi t√™n: {model_name}")
            st.write(f"T·ªïng s·ªë m√¥ h√¨nh hi·ªán t·∫°i: {len(st.session_state['neural_models'])}")

            # Hi·ªÉn th·ªã danh s√°ch m√¥ h√¨nh
            st.write("üìã Danh s√°ch c√°c m√¥ h√¨nh ƒë√£ l∆∞u:")
            model_names = [model["name"] for model in st.session_state["neural_models"]]
            st.write(", ".join(model_names))

            # Ho√†n t·∫•t ti·∫øn tr√¨nh
            progress_bar.progress(100)
            status_text.text("‚úÖ Hu·∫•n luy·ªán v√† logging ho√†n t·∫•t!")
            st.success(f"‚úÖ ƒê√£ log d·ªØ li·ªáu cho **Train_{st.session_state['run_name']}**!")
            
def preprocess_image(image):
    """X·ª≠ l√Ω ·∫£nh ƒë·∫ßu v√†o: Chuy·ªÉn v·ªÅ grayscale, resize, chu·∫©n h√≥a"""
    image = image.convert("L")
    image = image.resize((28, 28))  # Resize v·ªÅ k√≠ch th∆∞·ªõc ph√π h·ª£p
    img_array = np.array(image) / 255.0  # Chu·∫©n h√≥a pixel v·ªÅ [0,1]
    return img_array.reshape(1, -1)  # Chuy·ªÉn th√†nh vector 1D

def du_doan():
    st.title("üî¢ D·ª± ƒëo√°n ch·ªØ s·ªë vi·∫øt tay")

    # Ki·ªÉm tra xem ƒë√£ c√≥ m√¥ h√¨nh ch∆∞a
    if "neural_models" not in st.session_state or not st.session_state["neural_models"]:
        st.error("‚ö†Ô∏è Ch∆∞a c√≥ m√¥ h√¨nh n√†o ƒë∆∞·ª£c hu·∫•n luy·ªán. H√£y hu·∫•n luy·ªán m√¥ h√¨nh tr∆∞·ªõc.")
        return

    # Ch·ªçn m√¥ h√¨nh
    model_names = [model["name"] for model in st.session_state["neural_models"]]
    selected_model_name = st.selectbox("üîç Ch·ªçn m√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán:", model_names)
    selected_model = next(model["model"] for model in st.session_state["neural_models"] if model["name"] == selected_model_name)

    # Ch·ªçn c√°ch nh·∫≠p ·∫£nh: T·∫£i l√™n ho·∫∑c V·∫Ω
    option = st.radio("üìå Ch·ªçn c√°ch nh·∫≠p ·∫£nh:", ["üñºÔ∏è T·∫£i ·∫£nh l√™n", "‚úçÔ∏è V·∫Ω s·ªë"], key="input_option_radio")

    img_array = None  # Kh·ªüi t·∫°o ·∫£nh ƒë·∫ßu v√†o

    # 1Ô∏è‚É£ üñºÔ∏è N·∫øu t·∫£i ·∫£nh l√™n
    if option == "üñºÔ∏è T·∫£i ·∫£nh l√™n":
        uploaded_file = st.file_uploader("üì§ T·∫£i ·∫£nh ch·ªØ s·ªë vi·∫øt tay (28x28 pixel)", type=["png", "jpg", "jpeg"], key="upfile")
        if uploaded_file:
            image = Image.open(uploaded_file)
            st.image(image, caption="·∫¢nh ƒë√£ t·∫£i l√™n", use_container_width=True)
            img_array = preprocess_image(image)  # X·ª≠ l√Ω ·∫£nh

    # 2Ô∏è‚É£ ‚úçÔ∏è N·∫øu v·∫Ω s·ªë
    else:
        st.write("üé® V·∫Ω s·ªë trong khung d∆∞·ªõi ƒë√¢y:")
        
        # Canvas ƒë·ªÉ v·∫Ω
        canvas_result = st_canvas(
            fill_color="black",  # M√†u n·ªÅn
            stroke_width=10,
            stroke_color="black",
            background_color="white",
            height=250,
            width=250,
            drawing_mode="freedraw",
            key="canvas_draw"
        )

        # Khi ng∆∞·ªùi d√πng b·∫•m "D·ª± ƒëo√°n"
        if st.button("D·ª± ƒëo√°n s·ªë", key="dudoan"):
            if canvas_result.image_data is not None:
                # Chuy·ªÉn ƒë·ªïi ·∫£nh t·ª´ canvas th√†nh ƒë·ªãnh d·∫°ng PIL
                image = Image.fromarray((canvas_result.image_data[:, :, :3]).astype(np.uint8))
                img_array = preprocess_image(image)  # X·ª≠ l√Ω ·∫£nh
            else:
                st.error("‚ö†Ô∏è H√£y v·∫Ω m·ªôt s·ªë tr∆∞·ªõc khi d·ª± ƒëo√°n!")

    # üîç D·ª± ƒëo√°n n·∫øu c√≥ ·∫£nh ƒë·∫ßu v√†o h·ª£p l·ªá
    if img_array is not None:
        prediction = np.argmax(selected_model.predict(img_array), axis=1)[0]
        probabilities = selected_model.predict(img_array)[0]  # L·∫•y to√†n b·ªô x√°c su·∫•t c·ªßa c√°c l·ªõp

        # üèÜ Hi·ªÉn th·ªã k·∫øt qu·∫£ d·ª± ƒëo√°n
        st.success(f"üî¢ D·ª± ƒëo√°n: **{prediction}**")

        # üìä Hi·ªÉn th·ªã to√†n b·ªô ƒë·ªô tin c·∫≠y theo t·ª´ng l·ªõp
        st.write("### üî¢ ƒê·ªô tin c·∫≠y :")

        # üìä V·∫Ω bi·ªÉu ƒë·ªì ƒë·ªô tin c·∫≠y
        st.bar_chart(probabilities)

def show_experiment_selector():
    st.title("üìä MLflow Experiments")

    experiment_name = "neural"
    
    # L·∫•y danh s√°ch experiment
    experiments = mlflow.search_experiments()
    selected_experiment = next((exp for exp in experiments if exp.name == experiment_name), None)

    if not selected_experiment:
        st.error(f"‚ùå Experiment '{experiment_name}' kh√¥ng t·ªìn t·∫°i!")
        return

    st.subheader(f"üìå Experiment: {experiment_name}")
    st.write(f"**Experiment ID:** {selected_experiment.experiment_id}")
    st.write(f"**Tr·∫°ng th√°i:** {'Active' if selected_experiment.lifecycle_stage == 'active' else 'Deleted'}")
    st.write(f"**V·ªã tr√≠ l∆∞u tr·ªØ:** {selected_experiment.artifact_location}")

    # L·∫•y danh s√°ch runs trong experiment
    runs = mlflow.search_runs(experiment_ids=[selected_experiment.experiment_id])

    if runs.empty:
        st.warning("‚ö† Kh√¥ng c√≥ runs n√†o trong experiment n√†y.")
        return

    st.write("### üèÉ‚Äç‚ôÇÔ∏è C√°c Runs g·∫ßn ƒë√¢y:")

    # T·∫°o danh s√°ch run name v√† map v·ªõi run_id
    run_dict = {}
    for _, run in runs.iterrows():
        run_name = run.get("tags.mlflow.runName", f"Run {run['run_id'][:8]}")
        run_dict[run_name] = run["run_id"]  # Map run_name -> run_id

    # Ch·ªçn run theo t√™n
    selected_run_name = st.selectbox("üîç Ch·ªçn m·ªôt run:", list(run_dict.keys()),key="runname")
    selected_run_id = run_dict[selected_run_name]

    # L·∫•y th√¥ng tin c·ªßa run ƒë√£ ch·ªçn
    selected_run = mlflow.get_run(selected_run_id)

    if selected_run:
        st.subheader(f"üìå Th√¥ng tin Run: {selected_run_name}")
        st.write(f"**Run ID:** {selected_run_id}")
        st.write(f"**Tr·∫°ng th√°i:** {selected_run.info.status}")
        
        start_time_ms = selected_run.info.start_time
        start_time = datetime.fromtimestamp(start_time_ms / 1000).strftime("%Y-%m-%d %H:%M:%S") if start_time_ms else "Kh√¥ng c√≥ th√¥ng tin"

        st.write(f"**Th·ªùi gian ch·∫°y:** {start_time}")

        params = selected_run.data.params
        metrics = selected_run.data.metrics

        if params:
            st.write("### ‚öôÔ∏è Parameters:")
            st.json(params)

        if metrics:
            st.write("### üìä Metrics:")
            st.json(metrics)

    else:
        st.warning("‚ö† Kh√¥ng t√¨m th·∫•y th√¥ng tin cho run n√†y.")
        
def Neural():
    st.title("üñäÔ∏è MNIST Neural Network App")
    tab1, tab2, tab3, tab4 = st.tabs(["üìò Data", "‚öôÔ∏è Hu·∫•n luy·ªán", "üî¢ D·ª± ƒëo√°n", "üî•Mlflow"])

    with tab1:
        data()
        
    with tab2:
        split_data()
        train()
        
    with tab3:
        du_doan()   
    with tab4:
        show_experiment_selector()  

if __name__ == "__main__":
    Neural()