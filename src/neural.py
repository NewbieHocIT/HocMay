import tensorflow as tf
import tensorflow as tf
Sequential = tf.keras.models.Sequential
Dense = tf.keras.layers.Dense
Dropout = tf.keras.layers.Dropout
Adam = tf.keras.optimizers.Adam


import streamlit as st
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from PIL import Image
import pandas as pd
import os
import mlflow
from datetime import datetime
from sklearn.model_selection import cross_val_score
from streamlit_drawable_canvas import st_canvas


def load_mnist():
    X = np.load("data/mnist/X.npy")
    y = np.load("data/mnist/y.npy")
    return X, y

def data():
    st.header("MNIST Dataset")
    st.write("""
      **MNIST** lÃ  má»™t trong nhá»¯ng bá»™ dá»¯ liá»‡u ná»•i tiáº¿ng vÃ  phá»• biáº¿n nháº¥t trong cá»™ng Ä‘á»“ng há»c mÃ¡y, 
      Ä‘áº·c biá»‡t lÃ  trong cÃ¡c nghiÃªn cá»©u vá» nháº­n diá»‡n máº«u vÃ  phÃ¢n loáº¡i hÃ¬nh áº£nh.
  
      - Bá»™ dá»¯ liá»‡u bao gá»“m tá»•ng cá»™ng **70.000 áº£nh chá»¯ sá»‘ viáº¿t tay** tá»« **0** Ä‘áº¿n **9**, 
        má»—i áº£nh cÃ³ kÃ­ch thÆ°á»›c **28 x 28 pixel**.
      - Chia thÃ nh:
        - **Training set**: 60.000 áº£nh Ä‘á»ƒ huáº¥n luyá»‡n.
        - **Test set**: 10.000 áº£nh Ä‘á»ƒ kiá»ƒm tra.
      - Má»—i hÃ¬nh áº£nh lÃ  má»™t chá»¯ sá»‘ viáº¿t tay, Ä‘Æ°á»£c chuáº©n hÃ³a vÃ  chuyá»ƒn thÃ nh dáº¡ng grayscale (Ä‘en tráº¯ng).
  
      Dá»¯ liá»‡u nÃ y Ä‘Æ°á»£c sá»­ dá»¥ng rá»™ng rÃ£i Ä‘á»ƒ xÃ¢y dá»±ng cÃ¡c mÃ´ hÃ¬nh nháº­n diá»‡n chá»¯ sá»‘.
      """)

    st.subheader("Má»™t sá»‘ hÃ¬nh áº£nh tá»« MNIST Dataset")
    st.image("mnit.png", caption="Má»™t sá»‘ hÃ¬nh áº£nh tá»« MNIST Dataset", use_container_width=True)

    st.subheader("á»¨ng dá»¥ng thá»±c táº¿ cá»§a MNIST")
    st.write("""
      Bá»™ dá»¯ liá»‡u MNIST Ä‘Ã£ Ä‘Æ°á»£c sá»­ dá»¥ng trong nhiá»u á»©ng dá»¥ng nháº­n dáº¡ng chá»¯ sá»‘ viáº¿t tay, cháº³ng háº¡n nhÆ°:
      - Nháº­n diá»‡n sá»‘ trÃªn cÃ¡c hoÃ¡ Ä‘Æ¡n thanh toÃ¡n, biÃªn lai cá»­a hÃ ng.
      - Xá»­ lÃ½ chá»¯ sá»‘ trÃªn cÃ¡c bÆ°u kiá»‡n gá»­i qua bÆ°u Ä‘iá»‡n.
      - á»¨ng dá»¥ng trong cÃ¡c há»‡ thá»‘ng nháº­n diá»‡n tÃ i liá»‡u tá»± Ä‘á»™ng.
    """)

    st.subheader("VÃ­ dá»¥ vá» cÃ¡c mÃ´ hÃ¬nh há»c mÃ¡y vá»›i MNIST")
    st.write("""
      CÃ¡c mÃ´ hÃ¬nh há»c mÃ¡y phá»• biáº¿n Ä‘Ã£ Ä‘Æ°á»£c huáº¥n luyá»‡n vá»›i bá»™ dá»¯ liá»‡u MNIST bao gá»“m:
      - **Logistic Regression**
      - **Decision Trees**
      - **K-Nearest Neighbors (KNN)**
      - **Support Vector Machines (SVM)**
      - **Convolutional Neural Networks (CNNs)**
    """)

def split_data():
    st.title("ğŸ“Œ Chia dá»¯ liá»‡u Train/Test")

    # Äá»c dá»¯ liá»‡u
    X, y = load_mnist() 
    total_samples = X.shape[0]

    # Náº¿u chÆ°a cÃ³ cá» "data_split_done", Ä‘áº·t máº·c Ä‘á»‹nh lÃ  False
    if "data_split_done" not in st.session_state:
        st.session_state.data_split_done = False  

    # Thanh kÃ©o chá»n sá»‘ lÆ°á»£ng áº£nh Ä‘á»ƒ train
    num_samples = st.number_input("ğŸ“Œ Nháº­p sá»‘ lÆ°á»£ng áº£nh Ä‘á»ƒ train:", min_value=1000, max_value=70000, value=20000, step=1000)
    
    # Thanh kÃ©o chá»n tá»· lá»‡ Train/Test
    test_size = st.slider("ğŸ“Œ Chá»n % dá»¯ liá»‡u Test", 10, 50, 20)
    remaining_size = 100 - test_size
    val_size = st.slider("ğŸ“Œ Chá»n % dá»¯ liá»‡u Validation (trong pháº§n Train)", 0, 50, 15)
    st.write(f"ğŸ“Œ **Tá»· lá»‡ phÃ¢n chia:** Test={test_size}%, Validation={val_size}%, Train={remaining_size - val_size}%")

    if st.button("âœ… XÃ¡c nháº­n & LÆ°u", key="luu"):
        st.session_state.data_split_done = True  # ÄÃ¡nh dáº¥u Ä‘Ã£ chia dá»¯ liá»‡u
        
        if num_samples == total_samples:
            X_selected, y_selected = X, y
        else:
            X_selected, _, y_selected, _ = train_test_split(
                X, y, train_size=num_samples, stratify=y, random_state=42
            )

        # Chia train/test
        stratify_option = y_selected if len(np.unique(y_selected)) > 1 else None
        X_train_full, X_test, y_train_full, y_test = train_test_split(
            X_selected, y_selected, test_size=test_size/100, stratify=stratify_option, random_state=42
        )

        # Chia train/val
        if val_size > 0:
            stratify_option = y_train_full if len(np.unique(y_train_full)) > 1 else None
            X_train, X_val, y_train, y_val = train_test_split(
                X_train_full, y_train_full, test_size=val_size / (100 - test_size),
                stratify=stratify_option, random_state=42
            )
        else:
            X_train, y_train = X_train_full, y_train_full
            X_val, y_val = np.array([]), np.array([])  # Validation rá»—ng náº¿u val_size = 0

        # LÆ°u dá»¯ liá»‡u vÃ o session_state
        st.session_state.total_samples = num_samples
        st.session_state["neural_X_train"] = X_train
        st.session_state["neural_X_val"] = X_val
        st.session_state["neural_X_test"] = X_test
        st.session_state["neural_y_train"] = y_train
        st.session_state["neural_y_val"] = y_val
        st.session_state["neural_y_test"] = y_test
        st.session_state.test_size = X_test.shape[0]
        st.session_state.val_size = X_val.shape[0]
        st.session_state.train_size = X_train.shape[0]

        # Hiá»ƒn thá»‹ thÃ´ng tin chia dá»¯ liá»‡u
        summary_df = pd.DataFrame({
            "Táº­p dá»¯ liá»‡u": ["Train", "Validation", "Test"],
            "Sá»‘ lÆ°á»£ng máº«u": [X_train.shape[0], X_val.shape[0], X_test.shape[0]]
        })
        st.success("âœ… Dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c chia thÃ nh cÃ´ng!")
        st.table(summary_df)

    elif st.session_state.data_split_done:
        st.info("âœ… Dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c chia. Nháº¥n **ğŸ”„ Chia láº¡i dá»¯ liá»‡u** Ä‘á»ƒ thay Ä‘á»•i.")

def mlflow_input():
    DAGSHUB_MLFLOW_URI = "https://dagshub.com/NewbieHocIT/MocMayvsPython.mlflow"
    st.session_state['mlflow_url'] = DAGSHUB_MLFLOW_URI
    mlflow.set_tracking_uri(DAGSHUB_MLFLOW_URI)

    os.environ["MLFLOW_TRACKING_USERNAME"] = "NewbieHocIT"
    os.environ["MLFLOW_TRACKING_PASSWORD"] = "681dda9a41f9271a144aa94fa8624153a3c95696"

    mlflow.set_experiment("neural")
from tensorflow.python.keras.engine import data_adapter

def _is_distributed_dataset(ds):
    return isinstance(ds, data_adapter.input_lib.DistributedDatasetSpec)

data_adapter._is_distributed_dataset = _is_distributed_dataset

from tensorflow.python.keras.callbacks import Callback

# Callback tÃ¹y chá»‰nh Ä‘á»ƒ cáº­p nháº­t thanh tiáº¿n trÃ¬nh cho huáº¥n luyá»‡n
class ProgressBarCallback(Callback):
    def __init__(self, total_epochs, progress_bar, status_text, max_train_progress=80):
        super(ProgressBarCallback, self).__init__()
        self.total_epochs = total_epochs
        self.progress_bar = progress_bar
        self.status_text = status_text
        self.max_train_progress = max_train_progress  # Giá»›i háº¡n tiáº¿n trÃ¬nh huáº¥n luyá»‡n (80%)

    def on_epoch_begin(self, epoch, logs=None):
        progress = (epoch + 1) / self.total_epochs * self.max_train_progress
        self.progress_bar.progress(min(int(progress), self.max_train_progress))
        self.status_text.text(f"ğŸ› ï¸ Äang huáº¥n luyá»‡n mÃ´ hÃ¬nh... Epoch {epoch + 1}/{self.total_epochs}")

    def on_train_end(self, logs=None):
        self.progress_bar.progress(self.max_train_progress)
        self.status_text.text("âœ… Huáº¥n luyá»‡n mÃ´ hÃ¬nh hoÃ n táº¥t, Ä‘ang chuáº©n bá»‹ logging...")

def train():
    mlflow_input()

    # Kiá»ƒm tra xem dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c chia chÆ°a
    if (
        "neural_X_train" not in st.session_state
        or "neural_X_val" not in st.session_state
        or "neural_X_test" not in st.session_state
    ):
        st.error("âš ï¸ ChÆ°a cÃ³ dá»¯ liá»‡u! HÃ£y chia dá»¯ liá»‡u trÆ°á»›c.")
        return

    # Láº¥y dá»¯ liá»‡u tá»« session_state
    X_train = st.session_state["neural_X_train"]
    X_val = st.session_state["neural_X_val"]
    X_test = st.session_state["neural_X_test"]
    y_train = st.session_state["neural_y_train"]
    y_val = st.session_state["neural_y_val"]
    y_test = st.session_state["neural_y_test"]

    # Chuyá»ƒn Ä‘á»•i dá»¯ liá»‡u
    X_train = X_train.reshape(-1, 28 * 28) / 255.0
    X_test = X_test.reshape(-1, 28 * 28) / 255.0
    if X_val.size > 0:
        X_val = X_val.reshape(-1, 28 * 28) / 255.0

    st.header("âš™ï¸ Chá»n mÃ´ hÃ¬nh & Huáº¥n luyá»‡n")

    model_choice = st.selectbox(
        "Chá»n mÃ´ hÃ¬nh:", 
        ["Neural Network"], 
        key="neural_model_choice_selectbox"
    )

    if model_choice == "Neural Network":
        st.markdown("""
        - **ğŸ§  Neural Network (Máº¡ng nÆ¡-ron)** lÃ  má»™t mÃ´ hÃ¬nh há»c sÃ¢u cÃ³ kháº£ nÄƒng há»c cÃ¡c Ä‘áº·c trÆ°ng phá»©c táº¡p tá»« dá»¯ liá»‡u.
        - **Tham sá»‘ cáº§n chá»n:**  
            - **Sá»‘ lá»›p áº©n**: Sá»‘ lÆ°á»£ng lá»›p áº©n trong máº¡ng.  
            - **Sá»‘ node má»—i lá»›p**: Sá»‘ lÆ°á»£ng node trong má»—i lá»›p áº©n.  
            - **HÃ m kÃ­ch hoáº¡t**: HÃ m kÃ­ch hoáº¡t cho cÃ¡c lá»›p áº©n.  
            - **Tá»‘c Ä‘á»™ há»c**: Tá»‘c Ä‘á»™ há»c cá»§a thuáº­t toÃ¡n tá»‘i Æ°u.  
        """)
        
        num_layers = st.slider("Sá»‘ lá»›p áº©n", 1, 5, 2, key="neural_num_layers_slider")
        num_nodes = st.slider("Sá»‘ node má»—i lá»›p", 32, 256, 128, key="neural_num_nodes_slider")
        activation = st.selectbox("HÃ m kÃ­ch hoáº¡t", ["relu", "sigmoid", "tanh"], key="neural_activation_selectbox")
        epochs = st.slider("Sá»‘ epoch", 1, 50, 10, key="neural_epochs_slider")

        # XÃ¢y dá»±ng mÃ´ hÃ¬nh
        model = Sequential()
        model.add(Dense(num_nodes, input_shape=(28 * 28,), activation=activation))
        for _ in range(num_layers - 1):
            model.add(Dense(num_nodes, activation=activation))
        model.add(Dense(10, activation='softmax'))
        
        # BiÃªn dá»‹ch mÃ´ hÃ¬nh
        model.compile(optimizer=Adam(learning_rate=0.01),
                      loss='sparse_categorical_crossentropy',
                      metrics=['accuracy'])
    
    run_name = st.text_input("ğŸ”¹ Nháº­p tÃªn Run:", "Default_Run", key="neural_run_name_input")
    st.session_state["run_name"] = run_name if run_name else "default_run"
    
    if st.button("Huáº¥n luyá»‡n mÃ´ hÃ¬nh", key="neural_train_button"):
        with mlflow.start_run(run_name=f"Train_{st.session_state['run_name']}"):
            mlflow.log_param("test_size", st.session_state.test_size)
            mlflow.log_param("val_size", st.session_state.val_size)
            mlflow.log_param("train_size", st.session_state.train_size)
            mlflow.log_param("num_samples", st.session_state.total_samples)

            progress_bar = st.progress(0)  # Thanh tiáº¿n trÃ¬nh
            status_text = st.empty()  # Hiá»ƒn thá»‹ tráº¡ng thÃ¡i tá»«ng bÆ°á»›c

            # Giai Ä‘oáº¡n 1: Huáº¥n luyá»‡n (chiáº¿m 80% tiáº¿n trÃ¬nh)
            progress_callback = ProgressBarCallback(epochs, progress_bar, status_text, max_train_progress=80)

            if X_val.size > 0:
                history = model.fit(
                    X_train, y_train, 
                    epochs=epochs, 
                    validation_data=(X_val, y_val),
                    callbacks=[progress_callback],
                    verbose=0
                )
            else:
                history = model.fit(
                    X_train, y_train, 
                    epochs=epochs, 
                    callbacks=[progress_callback],
                    verbose=0
                )

            # Giai Ä‘oáº¡n 2: Logging vÃ  Ä‘Ã¡nh giÃ¡ (chiáº¿m 20% cÃ²n láº¡i)
            status_text.text("ğŸ“Š Äang Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh trÃªn test set...")
            progress_bar.progress(85)  # Cáº­p nháº­t tiáº¿n trÃ¬nh sau khi Ä‘Ã¡nh giÃ¡ test set
            test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)

            # Hiá»ƒn thá»‹ káº¿t quáº£
            if X_val.size > 0:
                train_accuracy = history.history['accuracy'][-1]
                val_accuracy = history.history['val_accuracy'][-1]
                st.success(f"âœ… **Äá»™ chÃ­nh xÃ¡c trÃªn táº­p train**: {train_accuracy:.4f}")
                st.success(f"âœ… **Äá»™ chÃ­nh xÃ¡c trÃªn táº­p validation**: {val_accuracy:.4f}")
            else:
                train_accuracy = history.history['accuracy'][-1]
                st.success(f"âœ… **Äá»™ chÃ­nh xÃ¡c trÃªn táº­p train**: {train_accuracy:.4f}")
            st.success(f"âœ… **Äá»™ chÃ­nh xÃ¡c trÃªn test set**: {test_acc:.4f}")

            # Logging vá»›i MLflow
            status_text.text("ğŸ“ Äang ghi log vÃ o MLflow...")
            progress_bar.progress(90)  # Cáº­p nháº­t tiáº¿n trÃ¬nh khi báº¯t Ä‘áº§u logging

            mlflow.log_param("model", model_choice)
            mlflow.log_param("num_layers", num_layers)
            mlflow.log_param("num_nodes", num_nodes)
            mlflow.log_param("activation", activation)
            mlflow.log_param("learning_rate", 0.01)
            mlflow.log_param("epochs", epochs)

            mlflow.log_metric("test_accuracy", test_acc)
            if X_val.size > 0:
                mlflow.log_metric("train_accuracy", train_accuracy)
                mlflow.log_metric("val_accuracy", val_accuracy)

            # LÆ°u mÃ´ hÃ¬nh
            model_path = f"model_{st.session_state['run_name']}.h5"
            model.save(model_path)
            mlflow.log_artifact(model_path)
            progress_bar.progress(95)  # Cáº­p nháº­t tiáº¿n trÃ¬nh khi lÆ°u mÃ´ hÃ¬nh

            # LÆ°u thÃ´ng tin mÃ´ hÃ¬nh vÃ o session_state
            if "neural_models" not in st.session_state:
                st.session_state["neural_models"] = []

            model_name = model_choice.lower().replace(" ", "_")
            model_name += f"_{num_layers}layers_{num_nodes}nodes_{activation}"
            existing_model = next((item for item in st.session_state["neural_models"] if item["name"] == model_name), None)

            if existing_model:
                count = 1
                new_model_name = f"{model_name}_{count}"
                while any(item["name"] == new_model_name for item in st.session_state["neural_models"]):
                    count += 1
                    new_model_name = f"{model_name}_{count}"
                model_name = new_model_name
                st.warning(f"âš ï¸ MÃ´ hÃ¬nh Ä‘Æ°á»£c lÆ°u vá»›i tÃªn: {model_name}")

            st.session_state["neural_models"].append({"name": model_name, "model": model})
            st.write(f"ğŸ”¹ MÃ´ hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c lÆ°u vá»›i tÃªn: {model_name}")
            st.write(f"Tá»•ng sá»‘ mÃ´ hÃ¬nh hiá»‡n táº¡i: {len(st.session_state['neural_models'])}")

            # Hiá»ƒn thá»‹ danh sÃ¡ch mÃ´ hÃ¬nh
            st.write("ğŸ“‹ Danh sÃ¡ch cÃ¡c mÃ´ hÃ¬nh Ä‘Ã£ lÆ°u:")
            model_names = [model["name"] for model in st.session_state["neural_models"]]
            st.write(", ".join(model_names))

            # HoÃ n táº¥t tiáº¿n trÃ¬nh
            progress_bar.progress(100)
            status_text.text("âœ… Huáº¥n luyá»‡n vÃ  logging hoÃ n táº¥t!")
            st.success(f"âœ… ÄÃ£ log dá»¯ liá»‡u cho **Train_{st.session_state['run_name']}**!")
            
def preprocess_image(image):
    """Xá»­ lÃ½ áº£nh Ä‘áº§u vÃ o: Chuyá»ƒn vá» grayscale, resize, chuáº©n hÃ³a"""
    image = image.convert("L")
    image = image.resize((28, 28))  # Resize vá» kÃ­ch thÆ°á»›c phÃ¹ há»£p
    img_array = np.array(image) / 255.0  # Chuáº©n hÃ³a pixel vá» [0,1]
    return img_array.reshape(1, -1)  # Chuyá»ƒn thÃ nh vector 1D

def du_doan():
    st.title("ğŸ”¢ Dá»± Ä‘oÃ¡n chá»¯ sá»‘ viáº¿t tay")

    # Kiá»ƒm tra xem Ä‘Ã£ cÃ³ mÃ´ hÃ¬nh chÆ°a
    if "neural_models" not in st.session_state or not st.session_state["neural_models"]:
        st.error("âš ï¸ ChÆ°a cÃ³ mÃ´ hÃ¬nh nÃ o Ä‘Æ°á»£c huáº¥n luyá»‡n. HÃ£y huáº¥n luyá»‡n mÃ´ hÃ¬nh trÆ°á»›c.")
        return

    # Chá»n mÃ´ hÃ¬nh
    model_names = [model["name"] for model in st.session_state["neural_models"]]
    selected_model_name = st.selectbox("ğŸ” Chá»n mÃ´ hÃ¬nh Ä‘Ã£ huáº¥n luyá»‡n:", model_names)
    selected_model = next(model["model"] for model in st.session_state["neural_models"] if model["name"] == selected_model_name)

    # Chá»n cÃ¡ch nháº­p áº£nh: Táº£i lÃªn hoáº·c Váº½
    option = st.radio("ğŸ“Œ Chá»n cÃ¡ch nháº­p áº£nh:", ["ğŸ–¼ï¸ Táº£i áº£nh lÃªn", "âœï¸ Váº½ sá»‘"], key="input_option_radio")

    img_array = None  # Khá»Ÿi táº¡o áº£nh Ä‘áº§u vÃ o

    # 1ï¸âƒ£ ğŸ–¼ï¸ Náº¿u táº£i áº£nh lÃªn
    if option == "ğŸ–¼ï¸ Táº£i áº£nh lÃªn":
        uploaded_file = st.file_uploader("ğŸ“¤ Táº£i áº£nh chá»¯ sá»‘ viáº¿t tay (28x28 pixel)", type=["png", "jpg", "jpeg"], key="upfile")
        if uploaded_file:
            image = Image.open(uploaded_file)
            st.image(image, caption="áº¢nh Ä‘Ã£ táº£i lÃªn", use_container_width=True)
            img_array = preprocess_image(image)  # Xá»­ lÃ½ áº£nh

    # 2ï¸âƒ£ âœï¸ Náº¿u váº½ sá»‘
    else:
        st.write("ğŸ¨ Váº½ sá»‘ trong khung dÆ°á»›i Ä‘Ã¢y:")
        
        # Canvas Ä‘á»ƒ váº½
        canvas_result = st_canvas(
            fill_color="black",  # MÃ u ná»n
            stroke_width=10,
            stroke_color="black",
            background_color="white",
            height=250,
            width=250,
            drawing_mode="freedraw",
            key="canvas_draw"
        )

        # Khi ngÆ°á»i dÃ¹ng báº¥m "Dá»± Ä‘oÃ¡n"
        if st.button("Dá»± Ä‘oÃ¡n sá»‘", key="dudoan"):
            if canvas_result.image_data is not None:
                # Chuyá»ƒn Ä‘á»•i áº£nh tá»« canvas thÃ nh Ä‘á»‹nh dáº¡ng PIL
                image = Image.fromarray((canvas_result.image_data[:, :, :3]).astype(np.uint8))
                img_array = preprocess_image(image)  # Xá»­ lÃ½ áº£nh
            else:
                st.error("âš ï¸ HÃ£y váº½ má»™t sá»‘ trÆ°á»›c khi dá»± Ä‘oÃ¡n!")

    # ğŸ” Dá»± Ä‘oÃ¡n náº¿u cÃ³ áº£nh Ä‘áº§u vÃ o há»£p lá»‡
    if img_array is not None:
        prediction = np.argmax(selected_model.predict(img_array), axis=1)[0]
        probabilities = selected_model.predict(img_array)[0]  # Láº¥y toÃ n bá»™ xÃ¡c suáº¥t cá»§a cÃ¡c lá»›p

        # ğŸ† Hiá»ƒn thá»‹ káº¿t quáº£ dá»± Ä‘oÃ¡n
        st.success(f"ğŸ”¢ Dá»± Ä‘oÃ¡n: **{prediction}**")

        # ğŸ“Š Hiá»ƒn thá»‹ toÃ n bá»™ Ä‘á»™ tin cáº­y theo tá»«ng lá»›p
        st.write("### ğŸ”¢ Äá»™ tin cáº­y :")

        # ğŸ“Š Váº½ biá»ƒu Ä‘á»“ Ä‘á»™ tin cáº­y
        st.bar_chart(probabilities)

def show_experiment_selector():
    st.title("ğŸ“Š MLflow Experiments")

    experiment_name = "neural"
    
    # Láº¥y danh sÃ¡ch experiment
    experiments = mlflow.search_experiments()
    selected_experiment = next((exp for exp in experiments if exp.name == experiment_name), None)

    if not selected_experiment:
        st.error(f"âŒ Experiment '{experiment_name}' khÃ´ng tá»“n táº¡i!")
        return

    st.subheader(f"ğŸ“Œ Experiment: {experiment_name}")
    st.write(f"**Experiment ID:** {selected_experiment.experiment_id}")
    st.write(f"**Tráº¡ng thÃ¡i:** {'Active' if selected_experiment.lifecycle_stage == 'active' else 'Deleted'}")
    st.write(f"**Vá»‹ trÃ­ lÆ°u trá»¯:** {selected_experiment.artifact_location}")

    # Láº¥y danh sÃ¡ch runs trong experiment
    runs = mlflow.search_runs(experiment_ids=[selected_experiment.experiment_id])

    if runs.empty:
        st.warning("âš  KhÃ´ng cÃ³ runs nÃ o trong experiment nÃ y.")
        return

    st.write("### ğŸƒâ€â™‚ï¸ CÃ¡c Runs gáº§n Ä‘Ã¢y:")

    # Táº¡o danh sÃ¡ch run name vÃ  map vá»›i run_id
    run_dict = {}
    for _, run in runs.iterrows():
        run_name = run.get("tags.mlflow.runName", f"Run {run['run_id'][:8]}")
        run_dict[run_name] = run["run_id"]  # Map run_name -> run_id

    # Chá»n run theo tÃªn
    selected_run_name = st.selectbox("ğŸ” Chá»n má»™t run:", list(run_dict.keys()),key="runname")
    selected_run_id = run_dict[selected_run_name]

    # Láº¥y thÃ´ng tin cá»§a run Ä‘Ã£ chá»n
    selected_run = mlflow.get_run(selected_run_id)

    if selected_run:
        st.subheader(f"ğŸ“Œ ThÃ´ng tin Run: {selected_run_name}")
        st.write(f"**Run ID:** {selected_run_id}")
        st.write(f"**Tráº¡ng thÃ¡i:** {selected_run.info.status}")
        
        start_time_ms = selected_run.info.start_time
        start_time = datetime.fromtimestamp(start_time_ms / 1000).strftime("%Y-%m-%d %H:%M:%S") if start_time_ms else "KhÃ´ng cÃ³ thÃ´ng tin"

        st.write(f"**Thá»i gian cháº¡y:** {start_time}")

        params = selected_run.data.params
        metrics = selected_run.data.metrics

        if params:
            st.write("### âš™ï¸ Parameters:")
            st.json(params)

        if metrics:
            st.write("### ğŸ“Š Metrics:")
            st.json(metrics)

    else:
        st.warning("âš  KhÃ´ng tÃ¬m tháº¥y thÃ´ng tin cho run nÃ y.")
        
def Neural():
    st.title("ğŸ–Šï¸ MNIST Neural Network App")
    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“˜ Data", "âš™ï¸ Huáº¥n luyá»‡n", "ğŸ”¢ Dá»± Ä‘oÃ¡n", "ğŸ”¥Mlflow"])

    with tab1:
        data()
        
    with tab2:
        split_data()
        train()
        
    with tab3:
        du_doan()   
    with tab4:
        show_experiment_selector()  

if __name__ == "__main__":
    Neural()