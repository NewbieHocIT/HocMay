import streamlit as st
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, classification_report
from sklearn.model_selection import train_test_split
import pickle
import mlflow
import dagshub
import os

# Khá»Ÿi táº¡o MLflow vÃ  DagsHub
def init_mlflow():
    try:
        dagshub.init(repo_owner='NewbieHocIT', repo_name='MocMayvsPython', mlflow=True)
        os.environ['MLFLOW_TRACKING_USERNAME'] = 'NewbieHocIT'
        os.environ['MLFLOW_TRACKING_PASSWORD'] = '681dda9a41f9271a144aa94fa8624153a3c95696'
        mlflow.set_tracking_uri("https://dagshub.com/NewbieHocIT/MocMayvsPython.mlflow")
        print("Káº¿t ná»‘i MLflow thÃ nh cÃ´ng!")
    except Exception as e:
        st.warning("KhÃ´ng thá»ƒ káº¿t ná»‘i vá»›i MLflow hoáº·c DagsHub. Vui lÃ²ng kiá»ƒm tra cÃ i Ä‘áº·t.")

def load_data():
    # Load táº­p train
    train_data = pd.read_csv("data/mnist/train.csv")
    X = train_data.iloc[:, 1:].values / 255.0
    y = train_data.iloc[:, 0].values
    return train_data, X, y

def show_sample_images():
    train_data = pd.read_csv("data/mnist/train.csv")
    unique_labels = train_data.iloc[:, 0].unique()
    fig, axes = plt.subplots(2, 5, figsize=(10, 5))
    label_count = 0
    
    for i, ax in enumerate(axes.flat):
        if label_count >= len(unique_labels):
            break
        sample = train_data[train_data.iloc[:, 0] == unique_labels[label_count]].iloc[0, 1:].values.reshape(28, 28)
        ax.imshow(sample, cmap='gray')
        ax.set_title(f"Label: {unique_labels[label_count]}", fontsize=10)
        ax.axis("off")
        label_count += 1
    st.pyplot(fig)

def plot_label_distribution(y):
    fig, ax = plt.subplots(figsize=(8, 5))
    pd.Series(y).value_counts().sort_index().plot(kind="bar", ax=ax, color="skyblue")
    ax.set_title("Label Distribution in Dataset")
    ax.set_xlabel("Digit Label")
    ax.set_ylabel("Count")
    st.pyplot(fig)

def display():
    st.title("ğŸ–¼ï¸ MNIST Classification using Decision Tree")
    st.header("ğŸ“Œ Step 1: Understanding Data")
    st.write("Below are some sample images from the dataset:")

    show_sample_images()

    st.write("ğŸ”¹ The pixel values are normalized by dividing by 255 to scale them between 0 and 1, which helps improve model performance and convergence speed.")
    train_data, X, y = load_data()
    st.write("ğŸ“Š First few rows of the dataset:")
    st.dataframe(train_data.head())
    st.write(f"ğŸ“ Dataset Shape: {train_data.shape}")

    st.write("ğŸ“Š Label Distribution:")
    plot_label_distribution(y)

    if st.button("Proceed to Training ğŸš€"):
        st.session_state['train_ready'] = True

    if 'train_ready' in st.session_state:
        st.header("ğŸ“Œ Step 2: Training Model")
        
        # Pháº§n chia dá»¯ liá»‡u vá»›i thanh trÆ°á»£t
        col1, col2 = st.columns(2)
        with col1:
            train_size = st.slider("ğŸ”¹ Chá»n tá»· lá»‡ dá»¯ liá»‡u Train (%)", min_value=0.0, max_value=100.0, value=70.0, step=1.0, key="train_size")
        with col2:
            val_size = st.slider("ğŸ”¸ Chá»n tá»· lá»‡ Validation (%)", min_value=0.0, max_value=100.0 - train_size, value=15.0, step=1.0, key="val_size")
        test_size = 100.0 - train_size - val_size  # Pháº§n cÃ²n láº¡i cho test

        if train_size == 0 or val_size == 0 or test_size == 0:
            st.error("ğŸš¨ Tá»· lá»‡ Train/Validation/Test khÃ´ng Ä‘Æ°á»£c báº±ng 0%. HÃ£y chá»n láº¡i.")
        else:
            train_ratio = train_size / 100.0
            val_ratio = val_size / 100.0
            test_ratio = test_size / 100.0

            st.write(f"ğŸ“Œ **Táº­p Train:** {train_size}%")
            st.write(f"ğŸ“Œ **Táº­p Validation:** {val_size}%")
            st.write(f"ğŸ“Œ **Táº­p Test:** {test_size}%")

            if st.button("Train Model ğŸ¯"):
                # Chia táº­p train thÃ nh táº­p train vÃ  táº­p validation
                X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=val_ratio, random_state=42)
                
                st.write("â³ Training Decision Tree Model...")
                model = DecisionTreeClassifier(criterion='entropy', max_depth=3, random_state=42)
                model.fit(X_train, y_train)
                
                with open("decision_tree_mnist_model.pkl", "wb") as model_file:
                    pickle.dump(model, model_file)
                st.session_state['model'] = model
                st.session_state['X_val'] = X_val
                st.session_state['y_val'] = y_val
                
                # ÄÃ¡nh giÃ¡ trÃªn táº­p validation
                y_val_pred = model.predict(X_val)
                accuracy = accuracy_score(y_val, y_val_pred)
                class_report = classification_report(y_val, y_val_pred, output_dict=True)
                
                st.success(f"âœ… Model Accuracy (Validation): {accuracy:.4f}")
                st.subheader("ğŸ“Š Classification Report (Validation)")
                st.dataframe(pd.DataFrame(class_report).transpose())

                # Log thÃ­ nghiá»‡m vÃ o MLflow
                try:
                    init_mlflow()
                    # Thiáº¿t láº­p thÃ­ nghiá»‡m vá»›i tÃªn cá»¥ thá»ƒ
                    mlflow.set_experiment("decision_tree_mnist")
                    with mlflow.start_run():
                        # Log cÃ¡c thÃ´ng sá»‘
                        mlflow.log_param("train_size", train_size)
                        mlflow.log_param("val_size", val_size)
                        mlflow.log_param("test_size", test_size)
                        mlflow.log_param("max_depth", 3)
                        mlflow.log_param("criterion", "entropy")

                        # Log cÃ¡c metrics
                        mlflow.log_metric("accuracy", accuracy)
                        for label, metrics in class_report.items():
                            if label.isdigit():
                                mlflow.log_metric(f"precision_{label}", metrics['precision'])
                                mlflow.log_metric(f"recall_{label}", metrics['recall'])
                                mlflow.log_metric(f"f1_score_{label}", metrics['f1-score'])

                        # Log mÃ´ hÃ¬nh
                        mlflow.sklearn.log_model(model, "decision_tree_model")
                        st.success("âœ… ThÃ­ nghiá»‡m Ä‘Ã£ Ä‘Æ°á»£c log vÃ o MLflow trong thÆ° má»¥c 'decision_tree_mnist'!")
                except Exception as e:
                    st.error(f"ğŸš¨ Lá»—i khi log thÃ­ nghiá»‡m: {e}")

    if 'model' in st.session_state:
        st.header("ğŸ“Œ Step 4: Predict Custom Digit")
        uploaded_file = st.file_uploader("ğŸ“¤ Upload grayscale image of a digit", type=["png", "jpg", "jpeg"])
        
        if uploaded_file is not None:
            from PIL import Image
            image = Image.open(uploaded_file).convert("L").resize((28, 28))
            image_array = np.array(image) / 255.0
            image_flatten = image_array.flatten().reshape(1, -1)
            
            st.image(image, caption="Uploaded Image", width=100)
            prediction = st.session_state['model'].predict(image_flatten)[0]
            st.success(f"ğŸ”® Predicted Label: {prediction}")

if __name__ == "__main__":
    display()